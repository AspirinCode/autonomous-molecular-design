{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleADDScenarioColab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X-nVUTt1wl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###initialize imports and dataset\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c conda-forge rdkit\n",
        "#!conda install pytorch torchvision cudatoolkit=9.0 -c pytorch -y\n",
        "#!pip3 install pyro-ppl\n",
        "\n",
        "!conda install -y --prefix /usr/local -c conda-forge rdkit joblib simdna\n",
        "!git clone https://github.com/deepchem/deepchem.git      # Clone deepchem source code from GitHub\n",
        "!cd deepchem && python setup.py install\n",
        "!ls -la /usr/local/lib/python3.7/site-packages/deepchem\n",
        "\n",
        "#!pip install -q tf-nightly-2.0-preview\n",
        "#%load_ext tensorboard\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import deepchem as dc\n",
        "from deepchem.utils.save import load_from_disk\n",
        "from deepchem.data import data_loader\n",
        "import random\n",
        "random.seed(0)\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "#import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kAWBKOM4LH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###shouldn't need to do this because the ground truth is in drive now\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U10M3eG2uFGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDGRjXhtb7fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "#!rm -rf ./logs/\n",
        "\n",
        "#log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4tgZh6x39li",
        "colab_type": "code",
        "outputId": "e7a3c861-6eb6-4a80-857c-a2bc11e29651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "dataset_file = \"drive/My Drive/ADD19 Datasets/enamineSubset10KGroundTruth.csv\"\n",
        "\n",
        "ground_truth_dataset = pd.read_csv(dataset_file)\n",
        "\n",
        "low_bace_dataset = ground_truth_dataset.sort_values(by=\"bace\")[:2500] #take 2.5K worst binder potential starters,shouldn't need copy\n",
        "\n",
        "top_5_percent_index = len(ground_truth_dataset) // 20\n",
        "top_5_percent_bace_cutoff = ground_truth_dataset.sort_values(by=\"bace\", ascending=False)[\"bace\"].tolist()[top_5_percent_index]\n",
        "\n",
        "print(\"Cutoff bace score for 95th percentile:\", top_5_percent_bace_cutoff)\n",
        "print(\"Columns of dataset: %s\" % str(ground_truth_dataset.columns.values))\n",
        "print(\"Number of examples in dataset: %s\" % str(ground_truth_dataset.shape[0]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.9630122\n",
            "Cutoff bace score for 95th percentile: 4.870083\n",
            "Columns of dataset: ['Index' 'SMILES' 'bace' 'esol' 'logD']\n",
            "Number of examples in dataset: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSj-0qqlcy1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###featurized ground truth for scoring\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "loader = dc.data.CSVLoader(tasks=[\"bace\", \"esol\", \"logD\"], smiles_field=\"SMILES\", featurizer=featurizer)\n",
        "dataset_feat = loader.featurize(dataset_file) #featurize the molecules from the ground truth dataset\n",
        "transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "ground_truth_for_scoring = transformer.transform(dataset_feat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "q4W87nF11wl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###initialize ground truth models and methods to access them\n",
        "\n",
        "def load_oracle_models():\n",
        "    \"\"\"Loads the pretrained ground truth models for evaluating molecules' properties on-the-fly.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    oracle : dict\n",
        "        A dictionary containing models mapped to their property keywords: \"bace\", \"esol\", \"logD\".\n",
        "    \"\"\"\n",
        "    bace_model = dc.models.GraphConvModel(n_tasks=1, mode='regression', batch_size=50, random_seed=0, model_dir=\"./models/bace\")\n",
        "    esol_model = dc.models.GraphConvModel(n_tasks=1, mode='regression', batch_size=50, random_seed=0, model_dir=\"./models/esol\")\n",
        "    logD_model = dc.models.GraphConvModel(n_tasks=1, mode='regression', batch_size=50, random_seed=0, model_dir=\"./models/logD\")\n",
        "    bace_model.restore()\n",
        "    esol_model.restore()\n",
        "    logD_model.restore()\n",
        "    oracle = {\"bace\":bace_model, \"esol\":esol_model, \"logD\":logD_model} #get each model via the named property\n",
        "    return oracle\n",
        "\n",
        "def query_oracle(dataset, oracle):\n",
        "    \"\"\"Evaluate molecules on-the-fly for their estimated bace, esol, and logD scores.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : pandas.DataFrame\n",
        "        The input dataset; must includes a field with smiles strings under keyword \"SMILES\".\n",
        "    oracle : dictionary( dc.models.GraphConvModel )\n",
        "        The pretrained ground truth value prediction models.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    results : pandas.DataFrame\n",
        "        Copy of input dataset with newly estimated bace, esol, and logD scores under those headers. \n",
        "    \"\"\"\n",
        "    query_file = \"./temp/oracle_eval.csv\"\n",
        "    dataset.to_csv(query_file)\n",
        "    \n",
        "    results = dataset.copy(deep=True) #defensive copy of input dataframe \n",
        "    \n",
        "    featurizer = dc.feat.ConvMolFeaturizer()\n",
        "    for prop in (\"bace\", \"esol\", \"logD\"):\n",
        "        #retrieve appropriate model from oracle\n",
        "        model = oracle[prop]\n",
        "        \n",
        "        #load, featurize, and normalize input dataset\n",
        "        loader = dc.data.CSVLoader(tasks=[prop], smiles_field=\"SMILES\",featurizer=featurizer)\n",
        "        dataset_feat = loader.featurize(query_file)\n",
        "        transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "        dataset_feat = transformer.transform(dataset_feat)\n",
        "        \n",
        "        #predict and assign property results to keyword\n",
        "        predicted = model.predict(dataset_feat)\n",
        "        results[prop] = predicted\n",
        "        \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpobjTVS1wl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###define Abstract Data Type to hold search information, including ensemble\n",
        "\n",
        "class Experimenter():\n",
        "    \"\"\"Class representing a research scientist/team going through the drug development process.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    N : int\n",
        "        Number of samples to initially train the experimenter ensemble on.\n",
        "    M : int\n",
        "        Number of molecules to purchase in each batch.\n",
        "    ensemble_size : int, optional\n",
        "        Number of models in experimenter ensemble.\n",
        "    epochs : int, optional\n",
        "        Number of epochs to train ensemble models for at each stage.\n",
        "    molecule_cost : int or float, optional\n",
        "        Monetary cost of purchasing a single molecule.\n",
        "    target_bounds : dictionary of str:tuples(floats), optional\n",
        "        Desired range for each property.\n",
        "    sampling_mode : string {\"thompson\", \"highest mean\", \"random\"}\n",
        "        The means of choosing the ensemble outputs/molecules.\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    ensemble : dictionary of deepchem.models.GrachConvModel\n",
        "        Models representing the experimenter knowledge/predictions and uncertainty.\n",
        "    history : list of dictionaries storing model attributes\n",
        "        Snapshots of the model state at each time step.\n",
        "    samples_seen : pandas.DataFrame\n",
        "        Ground truth values of the molecules seen before. Includes initial training set.\n",
        "    smiles_seen : list of str\n",
        "        SMILES strings of the molecules seen before.\n",
        "    selected_prediction : pandas.DataFrame\n",
        "        The molecule values used to make the next decision.\n",
        "    all_predictions : dict<int,pandas.DataFrame>\n",
        "        Predicted values of entire ensemble at this time step. Ensemble model keys (random seeds) map to model's prediction.\n",
        "    cost : int or float\n",
        "        Total monetary cost incurred at the current time.\n",
        "    number_molecules : int\n",
        "        Total number of molecules purchased at the current time.\n",
        "    time : int\n",
        "        Total number of days spent up to the current time.\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, N, M, ensemble_size=3, epochs=1, molecule_cost=200,\n",
        "                 target_bounds={\"bace\":(4, math.inf), \"esol\":(-5, math.inf), \"logD\":(-0.4, 5.6)}, sampling_method=\"highest mean\"):\n",
        "        self.N = N #initial samples\n",
        "        self.M = M #batch size\n",
        "        self.ensemble_size = ensemble_size\n",
        "        self.epochs = epochs\n",
        "        self.molecule_cost = molecule_cost\n",
        "        self.target_bounds = target_bounds\n",
        "        if sampling_method == \"thompson\" or sampling_method == \"highest mean\" or sampling_method == \"random\":\n",
        "            self.sampling_method = sampling_method\n",
        "        else:\n",
        "            raise ValueError(\"Input for sampling method was not allowed argument. Choices are thompson, highest mean, and random.\")\n",
        "        \n",
        "        self.ensemble = {i:dc.models.GraphConvModel(n_tasks=3, mode='regression', batch_size=20, random_seed=i, tensorboard=True) \n",
        "                         for i in range(self.ensemble_size)} #map each model to its seed\n",
        "        self.history = [] #save snapshot of model, on disk\n",
        "        self.samples_seen = None\n",
        "        self.smiles_seen = []\n",
        "        self.selected_prediction = pd.DataFrame()\n",
        "        self.all_predictions = {}\n",
        "        self.cost = 0\n",
        "        self.number_molecules = 0\n",
        "        self.time = 0 #days\n",
        "        \n",
        "        \n",
        "    def train_model(self, model, dataset):\n",
        "        \"\"\"Helper function to train a given ensemble model on a given dataset.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        model : Keras model (generally deepchem.GraphConvModel)\n",
        "            Model to be trained.\n",
        "        dataset : pandas.DataFrame\n",
        "            Dataset to train on. Must include \"SMILES\", \"bace\", \"esol\", and \"logD\" headers.\n",
        "            \n",
        "        \"\"\"\n",
        "        #convert DataFrame to CSV and read in as deepchem.Dataset via deepchem.CSVLoader\n",
        "        \n",
        "        #dataset_temp_file = \"./temp/training_dataset.csv\"\n",
        "        dataset.to_csv(\"training_dataset.csv\")\n",
        "        \n",
        "        !cp training_dataset.csv drive/My\\ Drive/\n",
        "\n",
        "\n",
        "        featurizer = dc.feat.ConvMolFeaturizer()\n",
        "        loader = dc.data.CSVLoader(tasks=[\"bace\", \"esol\", \"logD\"], smiles_field=\"SMILES\", featurizer=featurizer)\n",
        "\n",
        "        #dataset_feat = loader.featurize(dataset_temp_file)\n",
        "        dataset_feat = loader.featurize(\"training_dataset.csv\")\n",
        "        \n",
        "        transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "        dataset_feat = transformer.transform(dataset_feat)\n",
        "\n",
        "        model.fit(dataset_feat, nb_epoch=1, deterministic=True, restore=False)\n",
        "    \n",
        "    \n",
        "    def train_ensemble(self, dataset):\n",
        "        \"\"\"Helper function to train model ensemble.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset : pandas.Dataset\n",
        "            Dataset on which to train models. Must include \"SMILES\", \"bace\", \"esol\", and \"logD\" headers.\n",
        "        \n",
        "        \"\"\"\n",
        "        for model in self.ensemble.values():\n",
        "            self.train_model(model, dataset)\n",
        "\n",
        "    \n",
        "    def initial_training(self, verbose=False):\n",
        "        \"\"\"Train model ensemble for the first time on self.N samples randomly chosen from the 2500 lowest bace affinity-scored \n",
        "        molecules.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        verbose : bool\n",
        "            Whether to print progress updates.\n",
        "        \n",
        "        Notes\n",
        "        -----\n",
        "        If self.N > 2500, ensemble will be trained on 2500 samples.\n",
        "        Records first history object.\n",
        "        \n",
        "        \"\"\"\n",
        "        idx_range = self.N if self.N < low_bace_dataset.shape[0] else low_bace_dataset.shape[0]\n",
        "        rand_indices = random.sample(range(low_bace_dataset.shape[0]), k=idx_range) #select random row indices\n",
        "        \n",
        "        init_ensemble_dataset = pd.DataFrame()\n",
        "        for idx in rand_indices:\n",
        "            init_ensemble_dataset = init_ensemble_dataset.append( low_bace_dataset.iloc[idx], ignore_index=True )\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"Training set selected.\")\n",
        "            \n",
        "        self.samples_seen = init_ensemble_dataset ### collect the examples seen during initial training (ground truth values)\n",
        "        self.smiles_seen = init_ensemble_dataset[\"SMILES\"].tolist()\n",
        "        \n",
        "        #cost/time to initially train? free initial knowledge?\n",
        "        self.cost += self.molecule_cost * len(init_ensemble_dataset)\n",
        "        self.number_molecules += len(init_ensemble_dataset)\n",
        "        self.time = 0\n",
        "        \n",
        "\n",
        "        if self.sampling_method != \"random\":\n",
        "            if verbose:\n",
        "                print(\"Training ensemble...\")\n",
        "            self.train_ensemble(init_ensemble_dataset) #train ensemble on initial dataset, unless we are randomly sampling and do not need to        \n",
        "            if verbose:\n",
        "                print(\"Ensemble trained.\")\n",
        "                \n",
        "        self.record_history()\n",
        "\n",
        "                \n",
        "    def get_component_score(self, arr, keys):\n",
        "        \"\"\"Helper function to get the scaled \"goodness\" of the input scores.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        array : numpy.array\n",
        "             Array with bace, esol, and logD scores.\n",
        "        keys : collection of strings from {\"bace\", \"esol\", \"logD\"}\n",
        "            Which scores to incorporate into the overall goodness.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        numpy.array\n",
        "            Sum of component scores.\n",
        "        \n",
        "        \"\"\"\n",
        "        scores = []\n",
        "        if \"bace\" in keys:\n",
        "            #higher bace => higher score\n",
        "            bace = arr[:,0]\n",
        "            bace_range = self.target_bounds[\"bace\"]\n",
        "            scores.append( np.where(bace < bace_range[0], 0.2*bace-0.8, 0.05*bace-0.2) )\n",
        "            #dec penalty when score>low end of range\n",
        "        \n",
        "        if \"esol\" in keys:\n",
        "            esol = arr[:,1]\n",
        "            esol_range = self.target_bounds[\"esol\"]\n",
        "            scores.append( np.where(esol < esol_range[0], esol - np.absolute(esol-esol_range[1])**2, esol) )\n",
        "        \n",
        "        if \"logD\" in keys:\n",
        "            #logD within range is not penalized\n",
        "            logD = arr[:,2]\n",
        "            logD_range = self.target_bounds[\"logD\"]\n",
        "            #handle lower end of range\n",
        "            int_arr = np.where(logD < logD_range[0], logD - np.absolute(logD-logD_range[0]), logD)\n",
        "            #handle upper end of range\n",
        "            scores.append(np.where(int_arr > logD_range[1], int_arr - np.absolute(int_arr-logD_range[1]), int_arr) )\n",
        "\n",
        "        return sum(scores)\n",
        "        \n",
        "    \n",
        "    def score_and_select_top(self):\n",
        "        \"\"\"Scores all molecules and selects the top M for \"purchase\".\n",
        "        \n",
        "        \"\"\"\n",
        "        #featurizer = dc.feat.ConvMolFeaturizer()\n",
        "        #loader = dc.data.CSVLoader(tasks=[\"bace\", \"esol\", \"logD\"], smiles_field=\"SMILES\", featurizer=featurizer)\n",
        "        #dataset_feat = loader.featurize(dataset_file) #featurize the molecules from the ground truth dataset\n",
        "        #transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "        #dataset_feat = transformer.transform(dataset_feat)\n",
        "        \n",
        "        if self.sampling_method == \"highest mean\":\n",
        "            #generate and store all predictions\n",
        "            predicted = np.zeros( (len(ground_truth_for_scoring),3) )\n",
        "            for key in self.ensemble.keys:\n",
        "                pred = self.ensemble[key].predict(ground_truth_for_scoring)\n",
        "                predicted += pred #sum model predictions\n",
        "                self.all_predictions[key] = self.prediction_array_to_dataframe(pred) #store each prediction as a labeled dataframe\n",
        "            predicted /= len(self.ensemble) #avg model predictions\n",
        "            results_df = self.prediction_array_to_dataframe(predicted)\n",
        "            \n",
        "        elif self.sampling_method == \"thompson\":\n",
        "            #generate and store all predictions\n",
        "            self.all_predictions = {key : self.prediction_array_to_dataframe( self.ensemble[key].predict(ground_truth_for_scoring) )\n",
        "                                    for key in self.ensemble.keys()} #store all labeled dataframes       \n",
        "            #Thompson sampling\n",
        "            results_df = pd.DataFrame()\n",
        "            rand_pred_idx_range = len(self.ensemble) - 1 #random.randint range is inclusive on both ends\n",
        "            \n",
        "            for row_idx in range( len(ground_truth_for_scoring) ):\n",
        "                pred_key = random.randint(0, rand_pred_idx_range) #select random prediction array to get row from\n",
        "                pred_df = self.all_predictions[pred_key]\n",
        "                pred_row = pred_df.iloc[[row_idx]]\n",
        "                results_df = pd.concat([results_df, pred_row], sort=False)         \n",
        "        \n",
        "        elif self.sampling_method == \"random\":\n",
        "            ###randomly select up to M points from those not seen\n",
        "            unseen = ground_truth_dataset.loc[~ground_truth_dataset['SMILES'].isin(self.smiles_seen)] #remove prev seen\n",
        "            unseen = unseen.iloc[np.random.permutation(len(unseen))] #shuffle remaining samples\n",
        "            unseen = unseen[:self.M] if (len(unseen) > self.M) else unseen #select up to self.M samples\n",
        "            \n",
        "            self.samples_seen = pd.concat([self.samples_seen,unseen], sort=False)\n",
        "            self.smiles_seen = self.samples_seen[\"SMILES\"].tolist()\n",
        "            self.cost += self.molecule_cost * len(unseen)\n",
        "            self.number_molecules += len(unseen)\n",
        "            self.time += 28 #4 weeks to buy and experiment             \n",
        "            return \n",
        "            \n",
        "        self.selected_prediction = results_df #also store the dataframe with the data we chose to make decisions with\n",
        "        \n",
        "        unseen_predicted_rows = results_df.loc[~results_df['SMILES'].isin(self.smiles_seen)] #also remove predicted values previously seen\n",
        "        unseen_predicted_rows = unseen_predicted_rows.sort_values(by=\"goodness\", ascending=False) #sort predictions with highest goodness at top\n",
        "        \n",
        "        predicted_subset = unseen_predicted_rows[:self.M] if (len(unseen_predicted_rows) > self.M) else unseen_predicted_rows #select up to self.M samples from the predictions\n",
        "        predicted_subset_smiles = predicted_subset[\"SMILES\"].tolist()\n",
        "        \n",
        "        new_batch_ground_truth = ground_truth_dataset.loc[ground_truth_dataset['SMILES'].isin(predicted_subset_smiles)]\n",
        "        \n",
        "        self.samples_seen = pd.concat([self.samples_seen,new_batch_ground_truth], sort=False)\n",
        "        self.smiles_seen = self.samples_seen[\"SMILES\"].tolist()\n",
        "        self.cost += self.molecule_cost * len(new_batch_ground_truth)\n",
        "        self.number_molecules += len(new_batch_ground_truth)\n",
        "        self.time += 28 #4 weeks to buy and experiment\n",
        "    \n",
        "    \n",
        "    def prediction_array_to_dataframe(self, array):\n",
        "        #copy SMILES and assign calculated scores, store in self.predictions\n",
        "        df = pd.DataFrame()\n",
        "        df[\"SMILES\"] = ground_truth_dataset[\"SMILES\"]   \n",
        "        goodness = self.get_component_score(array, [\"bace\", \"esol\", \"logD\"])\n",
        "        df[\"bace\"] = array[:,0]\n",
        "        df[\"esol\"] = array[:,1]\n",
        "        df[\"logD\"] = array[:,2]\n",
        "        df[\"goodness\"] = goodness\n",
        "        return df\n",
        "        \n",
        "    \n",
        "    def record_history(self):\n",
        "        \"\"\"Stores model costs and experience for later analysis.\n",
        "        \n",
        "        Notes\n",
        "        -----\n",
        "        Does not save self.history attribute, in order to avoid redundantly storing the data in it.\n",
        "        Only saves attributes that change in each time step.\n",
        "        \n",
        "        \"\"\"\n",
        "        hist = {}\n",
        "        hist[\"samples_seen\"] = self.samples_seen\n",
        "        hist[\"smiles_seen\"] = self.smiles_seen\n",
        "        hist[\"cost\"] = self.cost\n",
        "        hist[\"number_molecules\"] = self.number_molecules\n",
        "        hist[\"time\"] = self.time\n",
        "        hist[\"selected prediction\"] = self.selected_prediction\n",
        "        hist[\"all predictions\"] = self.all_predictions\n",
        "        self.history.append(hist)\n",
        "     \n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Simple wrapper to automate calls to select molecules and update models. \n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        candidates : pandas.DataFrame\n",
        "            The candidate compounds that satisfy the given criteria.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Must be preceded by initial training of model ensemble.\n",
        "        \n",
        "        \"\"\"        \n",
        "        while len(self.samples_seen) < len(ground_truth_dataset): #search entire database, with early stopping\n",
        "            candidates = self.samples_seen.loc[self.samples_seen['bace'] >= top_5_percent_bace_cutoff] #find mols w/ high bace\n",
        "            \n",
        "            esol_lower_bound = self.target_bounds[\"esol\"][0]\n",
        "            candidates = candidates.loc[candidates['esol'] >= esol_lower_bound] #filter the insoluble mols\n",
        "            \n",
        "            logD_range = self.target_bounds[\"logD\"]\n",
        "            candidates = candidates.loc[( candidates['logD'] >= logD_range[0] ) \n",
        "                                                 & ( candidates['logD'] <= logD_range[1] )] #filter for logD in range\n",
        "              \n",
        "            if len(candidates) > 0:\n",
        "                print(\"Molecule within bounds and 95th percentile bace affinity found.\")\n",
        "                return candidates\n",
        "                \n",
        "            self.score_and_select_top()\n",
        "            self.record_history()\n",
        "            self.train_ensemble(self.samples_seen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pG_E7eT1wl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Step 1: load ground truth models and ensemble\n",
        "\n",
        "Step 2: train ensemble on N random data points (including ground truth values)\n",
        "\n",
        "Step 3: score all of the 10K molecules using the ensemble\n",
        "\n",
        "Step 4: take (\"buy\") the top M, and \"assess them experimentally\" (get their ground truth values)\n",
        "\n",
        "Step 5: add those samples to the training/seen set\n",
        "\n",
        "Step 6: retrain the ensemble\n",
        "\n",
        "Step 7: repeat (make 2-6 repeatable)\n",
        "\n",
        "Step 8: add some loops over N and M to generate plots of Hx vs N,M\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVz_6D1WkrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### ADD %%prun command to cell below to run and time with profiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YVdK0hJ1wmB",
        "colab_type": "code",
        "outputId": "061364f1-dd72-4470-9ace-8af9bb7321eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%prun\n",
        "#N = [96, 384, 1536] #initial train set size\n",
        "N = [96]\n",
        "#M = [96, 384, 1536] #batch size -> 96 wells, multiples\n",
        "M = [96]\n",
        "\n",
        "models = []\n",
        "\n",
        "for n in N:\n",
        "    for m in M:\n",
        "        e = Experimenter(n, m, ensemble_size=5, sampling_method='thompson')\n",
        "        models.append(e)\n",
        "        e.initial_training()\n",
        "        top_mols = e.run()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.337 s\n",
            "TIMING: dataset construction took 0.391 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.048 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 5: Average loss 1.24755\n",
            "TIMING: model fitting took 55.575 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.335 s\n",
            "TIMING: dataset construction took 0.389 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.049 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 5: Average loss 1.87386\n",
            "TIMING: model fitting took 61.571 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.347 s\n",
            "TIMING: dataset construction took 0.402 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.048 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 5: Average loss 1.75864\n",
            "TIMING: model fitting took 56.861 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.342 s\n",
            "TIMING: dataset construction took 0.398 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.049 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 5: Average loss 1.0557\n",
            "TIMING: model fitting took 58.183 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.332 s\n",
            "TIMING: dataset construction took 0.385 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.057 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 5: Average loss 1.51932\n",
            "TIMING: model fitting took 59.100 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.667 s\n",
            "TIMING: dataset construction took 0.753 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.095 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15: Average loss 0.940942\n",
            "TIMING: model fitting took 9.741 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.652 s\n",
            "TIMING: dataset construction took 0.747 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.097 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15: Average loss 1.05569\n",
            "TIMING: model fitting took 16.228 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.658 s\n",
            "TIMING: dataset construction took 0.752 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.102 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15: Average loss 1.13844\n",
            "TIMING: model fitting took 16.464 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.659 s\n",
            "TIMING: dataset construction took 0.749 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.096 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15: Average loss 0.946963\n",
            "TIMING: model fitting took 16.594 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 0.657 s\n",
            "TIMING: dataset construction took 0.748 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.108 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15: Average loss 1.04206\n",
            "TIMING: model fitting took 16.417 s\n",
            "Molecule within bounds and 95th percentile bace affinity found.\n",
            " "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1jAZ1PAcy6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_K7E9QqRMer",
        "colab_type": "code",
        "outputId": "7fc6ec26-e5ed-49d9-8c7e-8130de5119ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "top_mols\n",
        "print(e.history[1][\"number_molecules\"])\n",
        "\n",
        "baces = np.array(e.history[1][\"samples_seen\"][\"bace\"])\n",
        "n, bins, patches = plt.hist(baces, 50, facecolor='green')\n",
        "\n",
        "plt.xlabel('baces')\n",
        "plt.ylabel('Number of compounds')\n",
        "plt.title(r'Histogram of top mol bace scores')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWc39H6lKSbqyPykCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElzKdt-s1wmI",
        "colab_type": "code",
        "outputId": "d7e83d1e-7cdb-45af-e493-b72392a4f651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "for model in models:\n",
        "    costs = []\n",
        "    times = []\n",
        "    top_gt_bace_scores = []\n",
        "    goodnesses = []\n",
        "    \n",
        "    for hx in model.history:\n",
        "        costs.append(hx[\"cost\"])\n",
        "        times.append(hx[\"time\"])\n",
        "        top_gt_bace_scores.append(hx[\"samples_seen\"][\"bace\"].max()) #max ground truth score seen\n",
        "        if hx[\"selected prediction\"].empty:\n",
        "            goodnesses.append(0)\n",
        "        else:\n",
        "            goodnesses.append( hx[\"selected prediction\"][\"goodness\"].max() ) #max predicted goodness so far\n",
        "\n",
        "plt.plot(times,top_gt_bace_scores,'bs',label=\"top ground truth bace seen\")\n",
        "plt.plot(times,goodnesses,'rs',label=\"top pred goodness\")\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.title(r'Time vs top ground truth BACE score seen so far')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqfW8LDlqFP",
        "colab_type": "code",
        "outputId": "aea0b2d8-8b39-4739-dd45-cc30c050297d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "gt_bace = ground_truth_dataset[\"bace\"].tolist()\n",
        "low_bace = low_bace_dataset[\"bace\"].tolist()\n",
        "\n",
        "x = [i for i in range(len(gt_bace))]\n",
        "print(min(gt_bace))\n",
        "print(gt_bace[-1])\n",
        "\n",
        "plt.clf()\n",
        "plt.xlim([0,10000])\n",
        "plt.ylim([2.5,5.6])\n",
        "\n",
        "plt.plot(x,gt_bace,'bs',label=\"ground truth bace\")\n",
        "plt.plot(x[:2500],low_bace,'gs',label=\"low bace set\")\n",
        "\n",
        "plt.xlabel('index')\n",
        "plt.title(r'bace of gt dataset')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3942474999999996\n",
            "2.3942474999999996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgMREUFhICIiwP8HQgzBe21r8iMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}