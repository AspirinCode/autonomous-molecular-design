{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleADDScenarioColab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aPeOexnnN36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Step 1: load ground truth models and ensemble\n",
        "\n",
        "Step 2: train ensemble on N random data points (including ground truth values)\n",
        "\n",
        "Step 3: score all of the 10K molecules using the ensemble\n",
        "\n",
        "Step 4: take (\"buy\") the top M, and \"assess them experimentally\" (get their ground truth values)\n",
        "\n",
        "Step 5: add those samples to the training/seen set\n",
        "\n",
        "Step 6: retrain the ensemble\n",
        "\n",
        "Step 7: repeat (make 2-6 repeatable)\n",
        "\n",
        "Step 8: add some loops over N and M to generate plots of Hx vs N,M\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X-nVUTt1wl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af19bc4d-0f48-4ad4-f8d2-a90967fe9d1e"
      },
      "source": [
        "###initialize imports and dataset\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c conda-forge rdkit\n",
        "#!conda install pytorch torchvision cudatoolkit=9.0 -c pytorch -y\n",
        "#!pip3 install pyro-ppl\n",
        "\n",
        "!conda install -y --prefix /usr/local -c conda-forge rdkit joblib simdna\n",
        "!git clone https://github.com/deepchem/deepchem.git      # Clone deepchem source code from GitHub\n",
        "!cd deepchem && python setup.py install\n",
        "!ls -la /usr/local/lib/python3.7/site-packages/deepchem\n",
        "\n",
        "#!pip install -q tf-nightly-2.0-preview\n",
        "#%load_ext tensorboard\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import pandas as pd\n",
        "import deepchem as dc\n",
        "from deepchem.utils.save import load_from_disk\n",
        "from deepchem.data import data_loader\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import tensorflow as tf\n",
        "#import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-27 17:52:38--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70348401 (67M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  59%[==========>         ]  40.09M   200MB/s               \rMiniconda3-latest-L 100%[===================>]  67.09M   208MB/s    in 0.3s    \n",
            "\n",
            "2019-07-27 17:52:38 (208 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [70348401/70348401]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "reinstalling: python-3.7.3-h0371630_0 ...\n",
            "using -f (force) option\n",
            "Python 3.7.3\n",
            "reinstalling: ca-certificates-2019.1.23-0 ...\n",
            "using -f (force) option\n",
            "reinstalling: libgcc-ng-8.2.0-hdf63c60_1 ...\n",
            "using -f (force) option\n",
            "reinstalling: libstdcxx-ng-8.2.0-hdf63c60_1 ...\n",
            "using -f (force) option\n",
            "reinstalling: libffi-3.2.1-hd88cf55_4 ...\n",
            "using -f (force) option\n",
            "reinstalling: ncurses-6.1-he6710b0_1 ...\n",
            "using -f (force) option\n",
            "reinstalling: openssl-1.1.1b-h7b6447c_1 ...\n",
            "using -f (force) option\n",
            "reinstalling: xz-5.2.4-h14c3975_4 ...\n",
            "using -f (force) option\n",
            "reinstalling: yaml-0.1.7-had09818_2 ...\n",
            "using -f (force) option\n",
            "reinstalling: zlib-1.2.11-h7b6447c_3 ...\n",
            "using -f (force) option\n",
            "reinstalling: libedit-3.1.20181209-hc058e9b_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: readline-7.0-h7b6447c_5 ...\n",
            "using -f (force) option\n",
            "reinstalling: tk-8.6.8-hbc83047_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: sqlite-3.27.2-h7b6447c_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: asn1crypto-0.24.0-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: certifi-2019.3.9-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: chardet-3.0.4-py37_1 ...\n",
            "using -f (force) option\n",
            "reinstalling: idna-2.8-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: pycosat-0.6.3-py37h14c3975_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: pycparser-2.19-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: pysocks-1.6.8-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: ruamel_yaml-0.15.46-py37h14c3975_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: six-1.12.0-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: cffi-1.12.2-py37h2e261b9_1 ...\n",
            "using -f (force) option\n",
            "reinstalling: setuptools-41.0.0-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: cryptography-2.6.1-py37h1ba5d50_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: wheel-0.33.1-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: pip-19.0.3-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: pyopenssl-19.0.0-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: urllib3-1.24.1-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: requests-2.21.0-py37_0 ...\n",
            "using -f (force) option\n",
            "reinstalling: conda-4.6.14-py37_0 ...\n",
            "using -f (force) option\n",
            "using -f (force) option\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata: ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_0         396 KB  conda-forge\n",
            "    ca-certificates-2019.6.16  |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.6.16          |           py37_1         149 KB  conda-forge\n",
            "    conda-4.7.10               |           py37_0         3.0 MB  conda-forge\n",
            "    conda-package-handling-1.3.11|           py37_0         257 KB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_0         885 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |    h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_0        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libarchive-3.3.3           |    hb44662c_1005         1.4 MB  conda-forge\n",
            "    libblas-3.8.0              |      10_openblas           6 KB  conda-forge\n",
            "    libcblas-3.8.0             |      10_openblas           6 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_0         1.3 MB\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      10_openblas           6 KB  conda-forge\n",
            "    libopenblas-0.3.6          |       h6e990d7_5         7.7 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.0.10             |    h57b8799_1003         587 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.9              |       hee79883_2         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    lzo-2.10                   |    h14c3975_1000         319 KB  conda-forge\n",
            "    numpy-1.16.4               |   py37h95a1406_0         4.3 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openblas-0.3.6             |       h6e990d7_5         8.2 MB  conda-forge\n",
            "    openssl-1.1.1c             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-0.25.0              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.41                  |    hf484d3e_1003         249 KB  conda-forge\n",
            "    pillow-5.3.0               |py37h00a061d_1000         595 KB  conda-forge\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.1             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.0      |             py_0         219 KB  conda-forge\n",
            "    python-libarchive-c-2.8    |        py37_1004          21 KB  conda-forge\n",
            "    pytz-2019.1                |             py_0         227 KB  conda-forge\n",
            "    rdkit-2019.03.2            |   py37hb31dc5d_1        23.3 MB  conda-forge\n",
            "    tqdm-4.32.2                |             py_0          41 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.8          |       h516909a_0         907 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.0                 |       h3b9ef0a_0         928 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       116.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_0\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  conda-package-han~ conda-forge/linux-64::conda-package-handling-1.3.11-py37_0\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_0\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libarchive         conda-forge/linux-64::libarchive-3.3.3-hb44662c_1005\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-10_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-10_openblas\n",
            "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-10_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.6-h6e990d7_5\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.0.10-h57b8799_1003\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.9-hee79883_2\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  lzo                conda-forge/linux-64::lzo-2.10-h14c3975_1000\n",
            "  numpy              conda-forge/linux-64::numpy-1.16.4-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  openblas           conda-forge/linux-64::openblas-0.3.6-h6e990d7_5\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.0-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.41-hf484d3e_1003\n",
            "  pillow             conda-forge/linux-64::pillow-5.3.0-py37h00a061d_1000\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.1-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.0-py_0\n",
            "  python-libarchive~ conda-forge/linux-64::python-libarchive-c-2.8-py37_1004\n",
            "  pytz               conda-forge/noarch::pytz-2019.1-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.03.2-py37hb31dc5d_1\n",
            "  tqdm               conda-forge/noarch::tqdm-4.32.2-py_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.8-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.0-h3b9ef0a_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.1.23-0 --> conda-forge::ca-certificates-2019.6.16-hecc5488_0\n",
            "  certifi                pkgs/main::certifi-2019.3.9-py37_0 --> conda-forge::certifi-2019.6.16-py37_1\n",
            "  conda                      pkgs/main::conda-4.6.14-py37_0 --> conda-forge::conda-4.7.10-py37_0\n",
            "  openssl              pkgs/main::openssl-1.1.1b-h7b6447c_1 --> conda-forge::openssl-1.1.1c-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with current_repodata.json, will retry with next repodata source.\n",
            "Initial quick solve with frozen env failed.  Unfreezing env and trying again.\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed\n",
            "Initial quick solve with frozen env failed.  Unfreezing env and trying again.\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - joblib\n",
            "    - rdkit\n",
            "    - simdna\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cycler-0.10.0              |             py_1           8 KB  conda-forge\n",
            "    dbus-1.13.6                |       he372182_0         602 KB  conda-forge\n",
            "    expat-2.2.5                |    he1b5a44_1003         191 KB  conda-forge\n",
            "    gst-plugins-base-1.14.5    |       h0935bb2_0         6.8 MB  conda-forge\n",
            "    gstreamer-1.14.5           |       h36ae1b5_0         4.5 MB  conda-forge\n",
            "    joblib-0.13.2              |             py_0         180 KB  conda-forge\n",
            "    kiwisolver-1.1.0           |   py37hc9558a2_0          86 KB  conda-forge\n",
            "    matplotlib-3.1.1           |           py37_1           6 KB  conda-forge\n",
            "    matplotlib-base-3.1.1      |   py37he7580a8_1         6.7 MB  conda-forge\n",
            "    pyparsing-2.4.1.1          |             py_0          57 KB  conda-forge\n",
            "    pyqt-5.9.2                 |   py37hcca6a23_0         5.7 MB  conda-forge\n",
            "    qt-5.9.7                   |       h0c104cb_3        80.8 MB  conda-forge\n",
            "    scipy-1.3.0                |   py37h921218d_0        18.8 MB  conda-forge\n",
            "    simdna-0.4.2               |             py_0         627 KB  conda-forge\n",
            "    sip-4.19.8                 |py37hf484d3e_1000         290 KB  conda-forge\n",
            "    sqlite-3.29.0              |       h7b6447c_0         1.9 MB\n",
            "    tk-8.6.9                   |    hed695b0_1002         3.2 MB  conda-forge\n",
            "    tornado-6.0.3              |   py37h516909a_0         637 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       130.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_1\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.6-he372182_0\n",
            "  expat              conda-forge/linux-64::expat-2.2.5-he1b5a44_1003\n",
            "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.14.5-h0935bb2_0\n",
            "  gstreamer          conda-forge/linux-64::gstreamer-1.14.5-h36ae1b5_0\n",
            "  joblib             conda-forge/noarch::joblib-0.13.2-py_0\n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.1.0-py37hc9558a2_0\n",
            "  matplotlib         conda-forge/linux-64::matplotlib-3.1.1-py37_1\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.1.1-py37he7580a8_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.1.1-py_0\n",
            "  pyqt               conda-forge/linux-64::pyqt-5.9.2-py37hcca6a23_0\n",
            "  qt                 conda-forge/linux-64::qt-5.9.7-h0c104cb_3\n",
            "  scipy              conda-forge/linux-64::scipy-1.3.0-py37h921218d_0\n",
            "  simdna             conda-forge/noarch::simdna-0.4.2-py_0\n",
            "  sip                conda-forge/linux-64::sip-4.19.8-py37hf484d3e_1000\n",
            "  tornado            conda-forge/linux-64::tornado-6.0.3-py37h516909a_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  sqlite                                  3.27.2-h7b6447c_0 --> 3.29.0-h7b6447c_0\n",
            "  tk                         pkgs/main::tk-8.6.8-hbc83047_0 --> conda-forge::tk-8.6.9-hed695b0_1002\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "scipy-1.3.0          | 18.8 MB   | : 100% 1.0/1 [00:03<00:00,  3.49s/it]               \n",
            "joblib-0.13.2        | 180 KB    | : 100% 1.0/1 [00:00<00:00, 12.04it/s]\n",
            "gst-plugins-base-1.1 | 6.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.42s/it]               \n",
            "sip-4.19.8           | 290 KB    | : 100% 1.0/1 [00:00<00:00, 12.33it/s]\n",
            "tornado-6.0.3        | 637 KB    | : 100% 1.0/1 [00:00<00:00,  9.80s/it]               \n",
            "matplotlib-base-3.1. | 6.7 MB    | : 100% 1.0/1 [00:02<00:00, 12.72s/it]               \n",
            "sqlite-3.29.0        | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  2.36it/s]\n",
            "tk-8.6.9             | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.46it/s]\n",
            "qt-5.9.7             | 80.8 MB   | : 100% 1.0/1 [00:17<00:00, 17.27s/it]               \n",
            "expat-2.2.5          | 191 KB    | : 100% 1.0/1 [00:00<00:00, 14.79it/s]\n",
            "pyqt-5.9.2           | 5.7 MB    | : 100% 1.0/1 [00:03<00:00, 11.35s/it]               \n",
            "kiwisolver-1.1.0     | 86 KB     | : 100% 1.0/1 [00:00<00:00,  3.12it/s]                \n",
            "pyparsing-2.4.1.1    | 57 KB     | : 100% 1.0/1 [00:00<00:00, 26.29it/s]\n",
            "matplotlib-3.1.1     | 6 KB      | : 100% 1.0/1 [00:00<00:00, 35.77it/s]\n",
            "cycler-0.10.0        | 8 KB      | : 100% 1.0/1 [00:00<00:00, 37.69it/s]\n",
            "simdna-0.4.2         | 627 KB    | : 100% 1.0/1 [00:01<00:00,  3.88s/it]              \n",
            "dbus-1.13.6          | 602 KB    | : 100% 1.0/1 [00:00<00:00,  6.65it/s]\n",
            "gstreamer-1.14.5     | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.04it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Cloning into 'deepchem'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 28250 (delta 34), reused 28 (delta 9), pack-reused 28187\u001b[K\n",
            "Receiving objects: 100% (28250/28250), 434.98 MiB | 14.62 MiB/s, done.\n",
            "Resolving deltas: 100% (20806/20806), done.\n",
            "running install\n",
            "[pbr] Writing ChangeLog\n",
            "[pbr] Generating ChangeLog\n",
            "[pbr] ChangeLog complete (0.1s)\n",
            "[pbr] Generating AUTHORS\n",
            "[pbr] AUTHORS complete (0.2s)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/deepchem\n",
            "creating build/lib/deepchem/models\n",
            "copying deepchem/models/__init__.py -> build/lib/deepchem/models\n",
            "copying deepchem/models/multitask.py -> build/lib/deepchem/models\n",
            "copying deepchem/models/layers.py -> build/lib/deepchem/models\n",
            "copying deepchem/models/models.py -> build/lib/deepchem/models\n",
            "copying deepchem/models/losses.py -> build/lib/deepchem/models\n",
            "copying deepchem/models/keras_model.py -> build/lib/deepchem/models\n",
            "creating build/lib/deepchem/dock\n",
            "creating build/lib/deepchem/dock/tests\n",
            "copying deepchem/dock/tests/__init__.py -> build/lib/deepchem/dock/tests\n",
            "copying deepchem/dock/tests/test_pose_scoring.py -> build/lib/deepchem/dock/tests\n",
            "copying deepchem/dock/tests/test_docking.py -> build/lib/deepchem/dock/tests\n",
            "copying deepchem/dock/tests/test_binding_pocket.py -> build/lib/deepchem/dock/tests\n",
            "copying deepchem/dock/tests/test_pose_generation.py -> build/lib/deepchem/dock/tests\n",
            "creating build/lib/deepchem/models/sklearn_models\n",
            "copying deepchem/models/sklearn_models/__init__.py -> build/lib/deepchem/models/sklearn_models\n",
            "creating build/lib/deepchem/feat\n",
            "copying deepchem/feat/one_hot.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/graph_features.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/rdkit_grid_featurizer.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/__init__.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/adjacency_fingerprints.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/binding_pocket_features.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/smiles_featurizers.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/nnscore_utils.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/atomic_coordinates.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/mol_graphs.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/basic.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/raw_featurizer.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/coulomb_matrices.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/base_classes.py -> build/lib/deepchem/feat\n",
            "copying deepchem/feat/fingerprints.py -> build/lib/deepchem/feat\n",
            "creating build/lib/deepchem/models/tensorgraph\n",
            "creating build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/sequence_dnn.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/symmetry_function_regression.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/chemnet_models.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/__init__.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/ontology.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/text_cnn.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/gan.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/seqtoseq.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/unet.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/robust_multitask.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/scscore.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/resnet50.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/graph_models.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "copying deepchem/models/tensorgraph/models/atomic_conv.py -> build/lib/deepchem/models/tensorgraph/models\n",
            "creating build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_graph_features.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_coulomb_matrices.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_basic.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/__init__.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_mol_graphs.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_fingerprints.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_rdkit_grid_features.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_one_hot.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_binding_pocket_features.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_smiles_featurizers.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_convmol.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_features.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_sdf_reader.py -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/test_atomic_coordinates.py -> build/lib/deepchem/feat/tests\n",
            "creating build/lib/deepchem/utils\n",
            "creating build/lib/deepchem/utils/test\n",
            "copying deepchem/utils/test/__init__.py -> build/lib/deepchem/utils/test\n",
            "copying deepchem/utils/test/test_seq.py -> build/lib/deepchem/utils/test\n",
            "copying deepchem/utils/test/test_rdkit_util.py -> build/lib/deepchem/utils/test\n",
            "copying deepchem/utils/test/test_generator_evaluator.py -> build/lib/deepchem/utils/test\n",
            "creating build/lib/deepchem/molnet\n",
            "creating build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/qm8_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/sweetlead_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/delaney_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/nci_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/clearance_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/pdbbind_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/__init__.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/factors_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/hppb_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/thermosol_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/chembl_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/chembl_tasks.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/qm9_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/lipo_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/kaggle_features.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/muv_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/kaggle_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/ppb_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/uv_tasks.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/qm7_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/bbbc_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/bace_features.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/sider_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/hiv_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/uv_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/sampl_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/clintox_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/uspto_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/cell_counting_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/pcba_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/toxcast_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/bace_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/bbbp_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/hopv_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/tox21_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/kinase_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "copying deepchem/molnet/load_function/chembl25_datasets.py -> build/lib/deepchem/molnet/load_function\n",
            "creating build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_tensor_graph.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_textcnnmodel.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_estimators.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/__init__.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_layers_pickle.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_optimizers.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_gan.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_ontology.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_sequencednn.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_model_ops.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_nbr_list.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_graph_models.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_atomic_conv.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_layers_eager.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_sequential.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_resnet50.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_unet.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_symmetry_functions.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_layers.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_seqtoseq.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_chemnet_models.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/test_scscore.py -> build/lib/deepchem/models/tensorgraph/tests\n",
            "creating build/lib/deepchem/rl\n",
            "creating build/lib/deepchem/rl/envs\n",
            "copying deepchem/rl/envs/__init__.py -> build/lib/deepchem/rl/envs\n",
            "copying deepchem/rl/envs/tictactoe.py -> build/lib/deepchem/rl/envs\n",
            "copying deepchem/rl/envs/test_tictactoe.py -> build/lib/deepchem/rl/envs\n",
            "copying deepchem/__init__.py -> build/lib/deepchem\n",
            "creating build/lib/deepchem/molnet/tests\n",
            "copying deepchem/molnet/tests/__init__.py -> build/lib/deepchem/molnet/tests\n",
            "copying deepchem/molnet/tests/test_molnet.py -> build/lib/deepchem/molnet/tests\n",
            "copying deepchem/molnet/tests/test_dnasim.py -> build/lib/deepchem/molnet/tests\n",
            "creating build/lib/deepchem/data\n",
            "creating build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_drop.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_reload.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/__init__.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_support_generator.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_shuffle.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_data_loader.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_datasets.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_image_loader.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_load.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_fasta_loader.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_image_dataset.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/test_merge.py -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/__init__.py -> build/lib/deepchem/data\n",
            "copying deepchem/data/supports.py -> build/lib/deepchem/data\n",
            "copying deepchem/data/test_data_loader.py -> build/lib/deepchem/data\n",
            "copying deepchem/data/data_loader.py -> build/lib/deepchem/data\n",
            "copying deepchem/data/datasets.py -> build/lib/deepchem/data\n",
            "creating build/lib/deepchem/models/xgboost_models\n",
            "copying deepchem/models/xgboost_models/__init__.py -> build/lib/deepchem/models/xgboost_models\n",
            "copying deepchem/molnet/__init__.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/molnet/run_benchmark_models.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/molnet/check_availability.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/molnet/preset_hyper_parameters.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/molnet/dnasim.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/molnet/run_benchmark.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/molnet/run_benchmark_low_data.py -> build/lib/deepchem/molnet\n",
            "copying deepchem/models/tensorgraph/optimizers.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/__init__.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/chemnet_layers.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/graph_layers.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/model_ops.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/initializations.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/fcnet.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/regularizers.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/activations.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/symmetry_functions.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/robust_multitask.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/sequential.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/IRV.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/layers.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/progressive_multitask.py -> build/lib/deepchem/models/tensorgraph\n",
            "copying deepchem/models/tensorgraph/tensor_graph.py -> build/lib/deepchem/models/tensorgraph\n",
            "creating build/lib/deepchem/hyper\n",
            "copying deepchem/hyper/grid_search.py -> build/lib/deepchem/hyper\n",
            "copying deepchem/hyper/__init__.py -> build/lib/deepchem/hyper\n",
            "copying deepchem/hyper/gaussian_process.py -> build/lib/deepchem/hyper\n",
            "copying deepchem/utils/evaluate.py -> build/lib/deepchem/utils\n",
            "copying deepchem/utils/__init__.py -> build/lib/deepchem/utils\n",
            "copying deepchem/utils/conformers.py -> build/lib/deepchem/utils\n",
            "copying deepchem/utils/mol_xyz_util.py -> build/lib/deepchem/utils\n",
            "copying deepchem/utils/save.py -> build/lib/deepchem/utils\n",
            "copying deepchem/utils/rdkit_util.py -> build/lib/deepchem/utils\n",
            "copying deepchem/utils/genomics.py -> build/lib/deepchem/utils\n",
            "creating build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_reload.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/__init__.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_singletask_to_multitask.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_api.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_multitask.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_generalize.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_kerasmodel.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_overfit.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/test_predict.py -> build/lib/deepchem/models/tests\n",
            "copying deepchem/rl/__init__.py -> build/lib/deepchem/rl\n",
            "copying deepchem/rl/ppo.py -> build/lib/deepchem/rl\n",
            "copying deepchem/rl/a3c.py -> build/lib/deepchem/rl\n",
            "creating build/lib/deepchem/metalearning\n",
            "copying deepchem/metalearning/maml.py -> build/lib/deepchem/metalearning\n",
            "copying deepchem/metalearning/__init__.py -> build/lib/deepchem/metalearning\n",
            "creating build/lib/deepchem/metrics\n",
            "copying deepchem/metrics/__init__.py -> build/lib/deepchem/metrics\n",
            "copying deepchem/metrics/genomic_metrics.py -> build/lib/deepchem/metrics\n",
            "creating build/lib/deepchem/trans\n",
            "copying deepchem/trans/__init__.py -> build/lib/deepchem/trans\n",
            "copying deepchem/trans/transformers.py -> build/lib/deepchem/trans\n",
            "creating build/lib/deepchem/splits\n",
            "copying deepchem/splits/task_splitter.py -> build/lib/deepchem/splits\n",
            "copying deepchem/splits/__init__.py -> build/lib/deepchem/splits\n",
            "copying deepchem/splits/test_specified_index_splitter.py -> build/lib/deepchem/splits\n",
            "copying deepchem/splits/splitters.py -> build/lib/deepchem/splits\n",
            "creating build/lib/deepchem/hyper/tests\n",
            "copying deepchem/hyper/tests/__init__.py -> build/lib/deepchem/hyper/tests\n",
            "copying deepchem/hyper/tests/test_hyperparam_opt.py -> build/lib/deepchem/hyper/tests\n",
            "creating build/lib/deepchem/trans/tests\n",
            "copying deepchem/trans/tests/__init__.py -> build/lib/deepchem/trans/tests\n",
            "copying deepchem/trans/tests/test_transformers.py -> build/lib/deepchem/trans/tests\n",
            "copying deepchem/dock/__init__.py -> build/lib/deepchem/dock\n",
            "copying deepchem/dock/pose_scoring.py -> build/lib/deepchem/dock\n",
            "copying deepchem/dock/binding_pocket.py -> build/lib/deepchem/dock\n",
            "copying deepchem/dock/pose_generation.py -> build/lib/deepchem/dock\n",
            "copying deepchem/dock/docking.py -> build/lib/deepchem/dock\n",
            "creating build/lib/deepchem/metrics/tests\n",
            "copying deepchem/metrics/tests/test_genomics.py -> build/lib/deepchem/metrics/tests\n",
            "copying deepchem/metrics/tests/__init__.py -> build/lib/deepchem/metrics/tests\n",
            "copying deepchem/metrics/tests/metrics_test.py -> build/lib/deepchem/metrics/tests\n",
            "creating build/lib/deepchem/splits/tests\n",
            "copying deepchem/splits/tests/__init__.py -> build/lib/deepchem/splits/tests\n",
            "copying deepchem/splits/tests/test_task_splitter.py -> build/lib/deepchem/splits/tests\n",
            "copying deepchem/splits/tests/test_splitter.py -> build/lib/deepchem/splits/tests\n",
            "running egg_info\n",
            "creating deepchem.egg-info\n",
            "writing pbr to deepchem.egg-info/pbr.json\n",
            "writing deepchem.egg-info/PKG-INFO\n",
            "writing dependency_links to deepchem.egg-info/dependency_links.txt\n",
            "writing top-level names to deepchem.egg-info/top_level.txt\n",
            "[pbr] Processing SOURCES.txt\n",
            "writing manifest file 'deepchem.egg-info/SOURCES.txt'\n",
            "[pbr] In git context, generating filelist from git\n",
            "warning: no previously-included files found matching '.gitreview'\n",
            "warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'deepchem.egg-info/SOURCES.txt'\n",
            "copying deepchem/dock/tests/1jld_ligand.sdf -> build/lib/deepchem/dock/tests\n",
            "copying deepchem/dock/tests/1jld_protein.pdb -> build/lib/deepchem/dock/tests\n",
            "copying deepchem/feat/tests/3ws9_ligand.sdf -> build/lib/deepchem/feat/tests\n",
            "copying deepchem/feat/tests/3ws9_protein_fixer_rdkit.pdb -> build/lib/deepchem/feat/tests\n",
            "creating build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3bwf_ligand_hyd.pdb -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3bwf_ligand_hyd.pdbqt -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3bwf_protein_hyd.pdb -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3bwf_protein_hyd.pdbqt -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3zp9_ligand_hyd.pdb -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3zp9_ligand_hyd.pdbqt -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3zp9_protein_hyd.pdb -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3zp9_protein_hyd.pdbqt -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3zso_ligand_hyd.pdb -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/3zso_protein.pdb -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/chembl_25_small.csv -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/water.sdf -> build/lib/deepchem/feat/tests/data\n",
            "copying deepchem/feat/tests/data/water.sdf.csv -> build/lib/deepchem/feat/tests/data\n",
            "creating build/lib/deepchem/utils/test/data\n",
            "copying deepchem/utils/test/data/example.fasta -> build/lib/deepchem/utils/test/data\n",
            "copying deepchem/utils/test/data/example.fastq -> build/lib/deepchem/utils/test/data\n",
            "copying deepchem/models/tensorgraph/tests/chembl_25_small.csv -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/models/tensorgraph/tests/example_DTNN.mat -> build/lib/deepchem/models/tensorgraph/tests\n",
            "copying deepchem/.gitignore -> build/lib/deepchem\n",
            "creating build/lib/deepchem/tests\n",
            "copying deepchem/tests/test_init.py -> build/lib/deepchem/tests\n",
            "copying deepchem/data/tests/a_image.tif -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/example.fasta -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/mini_emols.csv -> build/lib/deepchem/data/tests\n",
            "copying deepchem/data/tests/no_labels.csv -> build/lib/deepchem/data/tests\n",
            "creating build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000003-num0.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000004-num4.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000005-num1.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000006-num4.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000007-num9.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000008-num5.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000009-num9.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000010-num0.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000011-num6.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/data/tests/images/000012-num9.png -> build/lib/deepchem/data/tests/images\n",
            "copying deepchem/models/tests/butina_example.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/example.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/example_DTNN.mat -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/example_classification.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/example_regression.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/feat_multitask_example.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/gaussian_cdf_example.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/gbd3k.pkl.gz -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/multitask_example.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/nnscore_example.pkl.gz -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/sparse_multitask_example.csv -> build/lib/deepchem/models/tests\n",
            "copying deepchem/models/tests/user_specified_example.csv -> build/lib/deepchem/models/tests\n",
            "creating build/lib/deepchem/rl/tests\n",
            "copying deepchem/rl/tests/test_a3c.py -> build/lib/deepchem/rl/tests\n",
            "copying deepchem/rl/tests/test_ppo.py -> build/lib/deepchem/rl/tests\n",
            "creating build/lib/deepchem/metalearning/tests\n",
            "copying deepchem/metalearning/tests/test_maml.py -> build/lib/deepchem/metalearning/tests\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/optimizers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/sequence_dnn.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/symmetry_function_regression.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/chemnet_models.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/ontology.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/text_cnn.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/gan.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/seqtoseq.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/unet.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/robust_multitask.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/scscore.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/resnet50.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/graph_models.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/models/atomic_conv.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models\n",
            "copying build/lib/deepchem/models/tensorgraph/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/chemnet_layers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_tensor_graph.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_textcnnmodel.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_estimators.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_layers_pickle.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_optimizers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_gan.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_ontology.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/example_DTNN.mat -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_sequencednn.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_model_ops.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_nbr_list.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_graph_models.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_atomic_conv.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_layers_eager.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_sequential.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_resnet50.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_unet.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/chembl_25_small.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_symmetry_functions.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_layers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_seqtoseq.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_chemnet_models.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/tests/test_scscore.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests\n",
            "copying build/lib/deepchem/models/tensorgraph/graph_layers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/model_ops.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/initializations.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/fcnet.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/regularizers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/activations.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/symmetry_functions.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/robust_multitask.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/sequential.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/IRV.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/layers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/progressive_multitask.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/tensorgraph/tensor_graph.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph\n",
            "copying build/lib/deepchem/models/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/example_classification.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_reload.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/feat_multitask_example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_singletask_to_multitask.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/example_regression.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/example_DTNN.mat -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_api.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_multitask.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/sparse_multitask_example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_generalize.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_kerasmodel.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/multitask_example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_overfit.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/user_specified_example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/test_predict.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/gaussian_cdf_example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/nnscore_example.pkl.gz -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/gbd3k.pkl.gz -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/tests/butina_example.csv -> /usr/local/lib/python3.7/site-packages/deepchem/models/tests\n",
            "copying build/lib/deepchem/models/multitask.py -> /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models/xgboost_models\n",
            "copying build/lib/deepchem/models/xgboost_models/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/xgboost_models\n",
            "copying build/lib/deepchem/models/layers.py -> /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/models/sklearn_models\n",
            "copying build/lib/deepchem/models/sklearn_models/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/models/sklearn_models\n",
            "copying build/lib/deepchem/models/models.py -> /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "copying build/lib/deepchem/models/losses.py -> /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "copying build/lib/deepchem/models/keras_model.py -> /usr/local/lib/python3.7/site-packages/deepchem/models\n",
            "copying build/lib/deepchem/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/data\n",
            "copying build/lib/deepchem/data/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/data\n",
            "copying build/lib/deepchem/data/supports.py -> /usr/local/lib/python3.7/site-packages/deepchem/data\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_drop.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_reload.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_support_generator.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_shuffle.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/example.fasta -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_data_loader.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/no_labels.csv -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_image_loader.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_load.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/mini_emols.csv -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_fasta_loader.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/test_image_dataset.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000009-num9.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000012-num9.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000008-num5.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000004-num4.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000007-num9.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000011-num6.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000006-num4.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000010-num0.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000005-num1.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/images/000003-num0.png -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests/images\n",
            "copying build/lib/deepchem/data/tests/test_merge.py -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/tests/a_image.tif -> /usr/local/lib/python3.7/site-packages/deepchem/data/tests\n",
            "copying build/lib/deepchem/data/test_data_loader.py -> /usr/local/lib/python3.7/site-packages/deepchem/data\n",
            "copying build/lib/deepchem/data/data_loader.py -> /usr/local/lib/python3.7/site-packages/deepchem/data\n",
            "copying build/lib/deepchem/data/datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/data\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/tests\n",
            "copying build/lib/deepchem/tests/test_init.py -> /usr/local/lib/python3.7/site-packages/deepchem/tests\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/metalearning\n",
            "copying build/lib/deepchem/metalearning/maml.py -> /usr/local/lib/python3.7/site-packages/deepchem/metalearning\n",
            "copying build/lib/deepchem/metalearning/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/metalearning\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/metalearning/tests\n",
            "copying build/lib/deepchem/metalearning/tests/test_maml.py -> /usr/local/lib/python3.7/site-packages/deepchem/metalearning/tests\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/rl\n",
            "copying build/lib/deepchem/rl/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/rl/envs\n",
            "copying build/lib/deepchem/rl/envs/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl/envs\n",
            "copying build/lib/deepchem/rl/envs/tictactoe.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl/envs\n",
            "copying build/lib/deepchem/rl/envs/test_tictactoe.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl/envs\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/rl/tests\n",
            "copying build/lib/deepchem/rl/tests/test_a3c.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl/tests\n",
            "copying build/lib/deepchem/rl/tests/test_ppo.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl/tests\n",
            "copying build/lib/deepchem/rl/ppo.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl\n",
            "copying build/lib/deepchem/rl/a3c.py -> /usr/local/lib/python3.7/site-packages/deepchem/rl\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "copying build/lib/deepchem/molnet/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/qm8_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/sweetlead_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/delaney_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/nci_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/clearance_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/pdbbind_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/factors_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/hppb_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/thermosol_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/chembl_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/chembl_tasks.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/qm9_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/lipo_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/kaggle_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/muv_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/kaggle_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/ppb_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/uv_tasks.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/qm7_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/bbbc_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/bace_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/sider_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/hiv_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/uv_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/sampl_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/clintox_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/uspto_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/cell_counting_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/pcba_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/toxcast_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/bace_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/bbbp_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/hopv_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/tox21_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/kinase_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/load_function/chembl25_datasets.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function\n",
            "copying build/lib/deepchem/molnet/run_benchmark_models.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "copying build/lib/deepchem/molnet/check_availability.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests\n",
            "copying build/lib/deepchem/molnet/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests\n",
            "copying build/lib/deepchem/molnet/tests/test_molnet.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests\n",
            "copying build/lib/deepchem/molnet/tests/test_dnasim.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests\n",
            "copying build/lib/deepchem/molnet/preset_hyper_parameters.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "copying build/lib/deepchem/molnet/dnasim.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "copying build/lib/deepchem/molnet/run_benchmark.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "copying build/lib/deepchem/molnet/run_benchmark_low_data.py -> /usr/local/lib/python3.7/site-packages/deepchem/molnet\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/metrics\n",
            "copying build/lib/deepchem/metrics/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/metrics\n",
            "copying build/lib/deepchem/metrics/genomic_metrics.py -> /usr/local/lib/python3.7/site-packages/deepchem/metrics\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests\n",
            "copying build/lib/deepchem/metrics/tests/test_genomics.py -> /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests\n",
            "copying build/lib/deepchem/metrics/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests\n",
            "copying build/lib/deepchem/metrics/tests/metrics_test.py -> /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/hyper\n",
            "copying build/lib/deepchem/hyper/grid_search.py -> /usr/local/lib/python3.7/site-packages/deepchem/hyper\n",
            "copying build/lib/deepchem/hyper/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/hyper\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/hyper/tests\n",
            "copying build/lib/deepchem/hyper/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/hyper/tests\n",
            "copying build/lib/deepchem/hyper/tests/test_hyperparam_opt.py -> /usr/local/lib/python3.7/site-packages/deepchem/hyper/tests\n",
            "copying build/lib/deepchem/hyper/gaussian_process.py -> /usr/local/lib/python3.7/site-packages/deepchem/hyper\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/evaluate.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/conformers.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/mol_xyz_util.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/save.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/rdkit_util.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "copying build/lib/deepchem/utils/genomics.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/utils/test\n",
            "copying build/lib/deepchem/utils/test/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils/test\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/utils/test/data\n",
            "copying build/lib/deepchem/utils/test/data/example.fasta -> /usr/local/lib/python3.7/site-packages/deepchem/utils/test/data\n",
            "copying build/lib/deepchem/utils/test/data/example.fastq -> /usr/local/lib/python3.7/site-packages/deepchem/utils/test/data\n",
            "copying build/lib/deepchem/utils/test/test_seq.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils/test\n",
            "copying build/lib/deepchem/utils/test/test_rdkit_util.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils/test\n",
            "copying build/lib/deepchem/utils/test/test_generator_evaluator.py -> /usr/local/lib/python3.7/site-packages/deepchem/utils/test\n",
            "copying build/lib/deepchem/.gitignore -> /usr/local/lib/python3.7/site-packages/deepchem\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/dock\n",
            "copying build/lib/deepchem/dock/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/1jld_ligand.sdf -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/test_pose_scoring.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/1jld_protein.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/test_docking.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/test_binding_pocket.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/tests/test_pose_generation.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock/tests\n",
            "copying build/lib/deepchem/dock/pose_scoring.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock\n",
            "copying build/lib/deepchem/dock/binding_pocket.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock\n",
            "copying build/lib/deepchem/dock/pose_generation.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock\n",
            "copying build/lib/deepchem/dock/docking.py -> /usr/local/lib/python3.7/site-packages/deepchem/dock\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/splits\n",
            "copying build/lib/deepchem/splits/task_splitter.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits\n",
            "copying build/lib/deepchem/splits/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits\n",
            "copying build/lib/deepchem/splits/test_specified_index_splitter.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/splits/tests\n",
            "copying build/lib/deepchem/splits/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits/tests\n",
            "copying build/lib/deepchem/splits/tests/test_task_splitter.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits/tests\n",
            "copying build/lib/deepchem/splits/tests/test_splitter.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits/tests\n",
            "copying build/lib/deepchem/splits/splitters.py -> /usr/local/lib/python3.7/site-packages/deepchem/splits\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/trans\n",
            "copying build/lib/deepchem/trans/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/trans\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/trans/tests\n",
            "copying build/lib/deepchem/trans/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/trans/tests\n",
            "copying build/lib/deepchem/trans/tests/test_transformers.py -> /usr/local/lib/python3.7/site-packages/deepchem/trans/tests\n",
            "copying build/lib/deepchem/trans/transformers.py -> /usr/local/lib/python3.7/site-packages/deepchem/trans\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/one_hot.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/graph_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/rdkit_grid_featurizer.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/adjacency_fingerprints.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_graph_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_coulomb_matrices.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_basic.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/__init__.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_mol_graphs.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "creating /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3bwf_protein_hyd.pdbqt -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3zp9_ligand_hyd.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3zp9_protein_hyd.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/water.sdf -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3bwf_ligand_hyd.pdbqt -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3zso_ligand_hyd.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/water.sdf.csv -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3zp9_protein_hyd.pdbqt -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3zp9_ligand_hyd.pdbqt -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3bwf_ligand_hyd.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/chembl_25_small.csv -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3zso_protein.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/data/3bwf_protein_hyd.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/data\n",
            "copying build/lib/deepchem/feat/tests/test_fingerprints.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_rdkit_grid_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_one_hot.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_binding_pocket_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_smiles_featurizers.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_convmol.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/3ws9_protein_fixer_rdkit.pdb -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_sdf_reader.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/3ws9_ligand.sdf -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/tests/test_atomic_coordinates.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat/tests\n",
            "copying build/lib/deepchem/feat/binding_pocket_features.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/smiles_featurizers.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/nnscore_utils.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/atomic_coordinates.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/mol_graphs.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/basic.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/raw_featurizer.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/coulomb_matrices.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/base_classes.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "copying build/lib/deepchem/feat/fingerprints.py -> /usr/local/lib/python3.7/site-packages/deepchem/feat\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/optimizers.py to optimizers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/sequence_dnn.py to sequence_dnn.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/symmetry_function_regression.py to symmetry_function_regression.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/chemnet_models.py to chemnet_models.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/ontology.py to ontology.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/text_cnn.py to text_cnn.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/gan.py to gan.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/seqtoseq.py to seqtoseq.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/unet.py to unet.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/robust_multitask.py to robust_multitask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/scscore.py to scscore.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/resnet50.py to resnet50.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/graph_models.py to graph_models.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/models/atomic_conv.py to atomic_conv.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/chemnet_layers.py to chemnet_layers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_tensor_graph.py to test_tensor_graph.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_textcnnmodel.py to test_textcnnmodel.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_estimators.py to test_estimators.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_layers_pickle.py to test_layers_pickle.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_optimizers.py to test_optimizers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_gan.py to test_gan.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_ontology.py to test_ontology.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_sequencednn.py to test_sequencednn.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_model_ops.py to test_model_ops.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_nbr_list.py to test_nbr_list.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_graph_models.py to test_graph_models.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_atomic_conv.py to test_atomic_conv.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_layers_eager.py to test_layers_eager.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_sequential.py to test_sequential.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_resnet50.py to test_resnet50.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_unet.py to test_unet.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_symmetry_functions.py to test_symmetry_functions.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_layers.py to test_layers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_seqtoseq.py to test_seqtoseq.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_chemnet_models.py to test_chemnet_models.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tests/test_scscore.py to test_scscore.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/graph_layers.py to graph_layers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/model_ops.py to model_ops.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/initializations.py to initializations.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/fcnet.py to fcnet.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/regularizers.py to regularizers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/activations.py to activations.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/symmetry_functions.py to symmetry_functions.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/robust_multitask.py to robust_multitask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/sequential.py to sequential.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/IRV.py to IRV.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/layers.py to layers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/progressive_multitask.py to progressive_multitask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tensorgraph/tensor_graph.py to tensor_graph.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_reload.py to test_reload.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_singletask_to_multitask.py to test_singletask_to_multitask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_api.py to test_api.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_multitask.py to test_multitask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_generalize.py to test_generalize.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_kerasmodel.py to test_kerasmodel.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_overfit.py to test_overfit.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/tests/test_predict.py to test_predict.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/multitask.py to multitask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/xgboost_models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/layers.py to layers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/sklearn_models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/models.py to models.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/losses.py to losses.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/models/keras_model.py to keras_model.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/supports.py to supports.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_drop.py to test_drop.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_reload.py to test_reload.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_support_generator.py to test_support_generator.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_shuffle.py to test_shuffle.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_data_loader.py to test_data_loader.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_datasets.py to test_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_image_loader.py to test_image_loader.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_load.py to test_load.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_fasta_loader.py to test_fasta_loader.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_image_dataset.py to test_image_dataset.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/tests/test_merge.py to test_merge.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/test_data_loader.py to test_data_loader.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/data_loader.py to data_loader.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/data/datasets.py to datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/tests/test_init.py to test_init.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metalearning/maml.py to maml.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metalearning/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metalearning/tests/test_maml.py to test_maml.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/envs/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/envs/tictactoe.py to tictactoe.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/envs/test_tictactoe.py to test_tictactoe.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/tests/test_a3c.py to test_a3c.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/tests/test_ppo.py to test_ppo.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/ppo.py to ppo.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/rl/a3c.py to a3c.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/qm8_datasets.py to qm8_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/sweetlead_datasets.py to sweetlead_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/delaney_datasets.py to delaney_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/nci_datasets.py to nci_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/clearance_datasets.py to clearance_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/pdbbind_datasets.py to pdbbind_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/factors_datasets.py to factors_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/hppb_datasets.py to hppb_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/thermosol_datasets.py to thermosol_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/chembl_datasets.py to chembl_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/chembl_tasks.py to chembl_tasks.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/qm9_datasets.py to qm9_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/lipo_datasets.py to lipo_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/kaggle_features.py to kaggle_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/muv_datasets.py to muv_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/kaggle_datasets.py to kaggle_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/ppb_datasets.py to ppb_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/uv_tasks.py to uv_tasks.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/qm7_datasets.py to qm7_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/bbbc_datasets.py to bbbc_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/bace_features.py to bace_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/sider_datasets.py to sider_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/hiv_datasets.py to hiv_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/uv_datasets.py to uv_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/sampl_datasets.py to sampl_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/clintox_datasets.py to clintox_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/uspto_datasets.py to uspto_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/cell_counting_datasets.py to cell_counting_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/pcba_datasets.py to pcba_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/toxcast_datasets.py to toxcast_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/bace_datasets.py to bace_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/bbbp_datasets.py to bbbp_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/hopv_datasets.py to hopv_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/tox21_datasets.py to tox21_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/kinase_datasets.py to kinase_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/load_function/chembl25_datasets.py to chembl25_datasets.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/run_benchmark_models.py to run_benchmark_models.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/check_availability.py to check_availability.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests/test_molnet.py to test_molnet.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/tests/test_dnasim.py to test_dnasim.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/preset_hyper_parameters.py to preset_hyper_parameters.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/dnasim.py to dnasim.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/run_benchmark.py to run_benchmark.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/molnet/run_benchmark_low_data.py to run_benchmark_low_data.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metrics/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metrics/genomic_metrics.py to genomic_metrics.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests/test_genomics.py to test_genomics.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/metrics/tests/metrics_test.py to metrics_test.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/hyper/grid_search.py to grid_search.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/hyper/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/hyper/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/hyper/tests/test_hyperparam_opt.py to test_hyperparam_opt.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/hyper/gaussian_process.py to gaussian_process.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/evaluate.py to evaluate.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/conformers.py to conformers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/mol_xyz_util.py to mol_xyz_util.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/save.py to save.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/rdkit_util.py to rdkit_util.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/genomics.py to genomics.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/test/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/test/test_seq.py to test_seq.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/test/test_rdkit_util.py to test_rdkit_util.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/utils/test/test_generator_evaluator.py to test_generator_evaluator.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/tests/test_pose_scoring.py to test_pose_scoring.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/tests/test_docking.py to test_docking.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/tests/test_binding_pocket.py to test_binding_pocket.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/tests/test_pose_generation.py to test_pose_generation.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/pose_scoring.py to pose_scoring.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/binding_pocket.py to binding_pocket.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/pose_generation.py to pose_generation.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/dock/docking.py to docking.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/task_splitter.py to task_splitter.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/test_specified_index_splitter.py to test_specified_index_splitter.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/tests/test_task_splitter.py to test_task_splitter.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/tests/test_splitter.py to test_splitter.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/splits/splitters.py to splitters.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/trans/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/trans/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/trans/tests/test_transformers.py to test_transformers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/trans/transformers.py to transformers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/one_hot.py to one_hot.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/graph_features.py to graph_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/rdkit_grid_featurizer.py to rdkit_grid_featurizer.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/adjacency_fingerprints.py to adjacency_fingerprints.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_graph_features.py to test_graph_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_coulomb_matrices.py to test_coulomb_matrices.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_basic.py to test_basic.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_mol_graphs.py to test_mol_graphs.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_fingerprints.py to test_fingerprints.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_rdkit_grid_features.py to test_rdkit_grid_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_one_hot.py to test_one_hot.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_binding_pocket_features.py to test_binding_pocket_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_smiles_featurizers.py to test_smiles_featurizers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_convmol.py to test_convmol.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_features.py to test_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_sdf_reader.py to test_sdf_reader.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/tests/test_atomic_coordinates.py to test_atomic_coordinates.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/binding_pocket_features.py to binding_pocket_features.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/smiles_featurizers.py to smiles_featurizers.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/nnscore_utils.py to nnscore_utils.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/atomic_coordinates.py to atomic_coordinates.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/mol_graphs.py to mol_graphs.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/basic.py to basic.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/raw_featurizer.py to raw_featurizer.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/coulomb_matrices.py to coulomb_matrices.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/base_classes.py to base_classes.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/site-packages/deepchem/feat/fingerprints.py to fingerprints.cpython-37.pyc\n",
            "running install_egg_info\n",
            "Copying deepchem.egg-info to /usr/local/lib/python3.7/site-packages/deepchem-2.2.1.dev125-py3.7.egg-info\n",
            "running install_scripts\n",
            "/content/deepchem/.eggs/pbr-5.4.1-py3.7.egg/pbr/packaging.py:410: EasyInstallDeprecationWarning: Use get_header\n",
            "  header = easy_install.get_script_header(\"\", executable, is_wininst)\n",
            "total 72\n",
            "drwxr-xr-x 16 root root 4096 Jul 27 17:57 .\n",
            "drwxr-xr-x 76 root root 4096 Jul 27 17:57 ..\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 data\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 dock\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 feat\n",
            "-rw-r--r--  1 root root   76 Jul 27 17:57 .gitignore\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 hyper\n",
            "-rw-r--r--  1 root root  397 Jul 27 17:57 __init__.py\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 metalearning\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 metrics\n",
            "drwxr-xr-x  7 root root 4096 Jul 27 17:57 models\n",
            "drwxr-xr-x  5 root root 4096 Jul 27 17:57 molnet\n",
            "drwxr-xr-x  2 root root 4096 Jul 27 17:57 __pycache__\n",
            "drwxr-xr-x  5 root root 4096 Jul 27 17:57 rl\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 splits\n",
            "drwxr-xr-x  3 root root 4096 Jul 27 17:57 tests\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 trans\n",
            "drwxr-xr-x  4 root root 4096 Jul 27 17:57 utils\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kAWBKOM4LH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###shouldn't need to do this because the ground truth is in drive now\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U10M3eG2uFGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDGRjXhtb7fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "#!rm -rf ./logs/\n",
        "\n",
        "#log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4tgZh6x39li",
        "colab_type": "code",
        "outputId": "c6560149-2598-48df-e4f7-9c9b36c257ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dataset_file = \"drive/My Drive/ADD19 Datasets/enamineSubset10KGroundTruth.csv\"\n",
        "\n",
        "ground_truth_dataset = pd.read_csv(dataset_file)\n",
        "\n",
        "low_bace_dataset = ground_truth_dataset.sort_values(by=\"bace\")[:2500] #take 2.5K worst binder potential starters,shouldn't need copy\n",
        "\n",
        "top_5_percent_index = len(ground_truth_dataset) // 20\n",
        "top_5_percent_bace_cutoff = ground_truth_dataset.sort_values(by=\"bace\", ascending=False)[\"bace\"].tolist()[top_5_percent_index]\n",
        "\n",
        "print(\"Cutoff bace score for 95th percentile:\", top_5_percent_bace_cutoff)\n",
        "print(\"Columns of dataset: %s\" % str(ground_truth_dataset.columns.values))\n",
        "print(\"Number of examples in dataset: %s\" % str(ground_truth_dataset.shape[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cutoff bace score for 95th percentile: 4.870083\n",
            "Columns of dataset: ['Index' 'SMILES' 'bace' 'esol' 'logD']\n",
            "Number of examples in dataset: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSj-0qqlcy1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###featurized ground truth for scoring\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "loader = dc.data.CSVLoader(tasks=[\"bace\", \"esol\", \"logD\"], smiles_field=\"SMILES\", featurizer=featurizer)\n",
        "dataset_feat = loader.featurize(dataset_file) #featurize the molecules from the ground truth dataset\n",
        "transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "ground_truth_for_scoring = transformer.transform(dataset_feat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "q4W87nF11wl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###initialize ground truth models and methods to access them\n",
        "\n",
        "def load_oracle_models():\n",
        "    \"\"\"Loads the pretrained ground truth models for evaluating molecules' properties on-the-fly.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    oracle : dict\n",
        "        A dictionary containing models mapped to their property keywords: \"bace\", \"esol\", \"logD\".\n",
        "    \"\"\"\n",
        "    bace_model = dc.models.GraphConvModel(n_tasks=1, mode='regression', batch_size=50, random_seed=0, model_dir=\"./models/bace\")\n",
        "    esol_model = dc.models.GraphConvModel(n_tasks=1, mode='regression', batch_size=50, random_seed=0, model_dir=\"./models/esol\")\n",
        "    logD_model = dc.models.GraphConvModel(n_tasks=1, mode='regression', batch_size=50, random_seed=0, model_dir=\"./models/logD\")\n",
        "    bace_model.restore()\n",
        "    esol_model.restore()\n",
        "    logD_model.restore()\n",
        "    oracle = {\"bace\":bace_model, \"esol\":esol_model, \"logD\":logD_model} #get each model via the named property\n",
        "    return oracle\n",
        "\n",
        "def query_oracle(dataset, oracle):\n",
        "    \"\"\"Evaluate molecules on-the-fly for their estimated bace, esol, and logD scores.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : pandas.DataFrame\n",
        "        The input dataset; must includes a field with smiles strings under keyword \"SMILES\".\n",
        "    oracle : dictionary( dc.models.GraphConvModel )\n",
        "        The pretrained ground truth value prediction models.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    results : pandas.DataFrame\n",
        "        Copy of input dataset with newly estimated bace, esol, and logD scores under those headers. \n",
        "    \"\"\"\n",
        "    query_file = \"./temp/oracle_eval.csv\"\n",
        "    dataset.to_csv(query_file)\n",
        "    \n",
        "    results = dataset.copy(deep=True) #defensive copy of input dataframe \n",
        "    \n",
        "    featurizer = dc.feat.ConvMolFeaturizer()\n",
        "    for prop in (\"bace\", \"esol\", \"logD\"):\n",
        "        #retrieve appropriate model from oracle\n",
        "        model = oracle[prop]\n",
        "        \n",
        "        #load, featurize, and normalize input dataset\n",
        "        loader = dc.data.CSVLoader(tasks=[prop], smiles_field=\"SMILES\",featurizer=featurizer)\n",
        "        dataset_feat = loader.featurize(query_file)\n",
        "        transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "        dataset_feat = transformer.transform(dataset_feat)\n",
        "        \n",
        "        #predict and assign property results to keyword\n",
        "        predicted = model.predict(dataset_feat)\n",
        "        results[prop] = predicted\n",
        "        \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpobjTVS1wl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###define Abstract Data Type to hold search information, including ensemble\n",
        "\n",
        "class Experimenter():\n",
        "    \"\"\"Class representing a research scientist/team going through the drug development process.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    N : int\n",
        "        Number of samples to initially train the experimenter ensemble on.\n",
        "    M : int\n",
        "        Number of molecules to purchase in each batch.\n",
        "    ensemble_size : int, optional\n",
        "        Number of models in experimenter ensemble.\n",
        "    epochs : int, optional\n",
        "        Number of epochs to train ensemble models for at each stage.\n",
        "    molecule_cost : int or float, optional\n",
        "        Monetary cost of purchasing a single molecule.\n",
        "    target_bounds : dictionary of str:tuples(floats), optional\n",
        "        Desired range for each property.\n",
        "    sampling_mode : string {\"thompson\", \"highest mean\", \"random\"}\n",
        "        The means of choosing the ensemble outputs/molecules.\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    ensemble : dictionary of deepchem.models.GrachConvModel\n",
        "        Models representing the experimenter knowledge/predictions and uncertainty.\n",
        "    history : list of dictionaries storing model attributes\n",
        "        Snapshots of the model state at each time step.\n",
        "    samples_seen : pandas.DataFrame\n",
        "        Ground truth values of the molecules seen before. Includes initial training set.\n",
        "    smiles_seen : list of str\n",
        "        SMILES strings of the molecules seen before.\n",
        "    selected_prediction : pandas.DataFrame\n",
        "        The molecule values used to make the next decision.\n",
        "    all_predictions : dict<int,pandas.DataFrame>\n",
        "        Predicted values of entire ensemble at this time step. Ensemble model keys (random seeds) map to model's prediction.\n",
        "    cost : int or float\n",
        "        Total monetary cost incurred at the current time.\n",
        "    number_molecules : int\n",
        "        Total number of molecules purchased at the current time.\n",
        "    time : int\n",
        "        Total number of days spent up to the current time.\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, N, M, ensemble_size=3, epochs=10, molecule_cost=200,\n",
        "                 target_bounds={\"bace\":(4, math.inf), \"esol\":(-5, math.inf), \"logD\":(-0.4, 5.6)}, sampling_method=\"highest mean\"):\n",
        "        self.N = N #initial samples\n",
        "        self.M = M #batch size\n",
        "        self.ensemble_size = ensemble_size\n",
        "        self.epochs = epochs\n",
        "        self.molecule_cost = molecule_cost\n",
        "        self.target_bounds = target_bounds\n",
        "        if sampling_method == \"thompson\" or sampling_method == \"highest mean\" or sampling_method == \"random\":\n",
        "            self.sampling_method = sampling_method\n",
        "        else:\n",
        "            raise ValueError(\"Input for sampling method was not allowed argument. Choices are thompson, highest mean, and random.\")\n",
        "        \n",
        "        self.ensemble = {i:dc.models.GraphConvModel(n_tasks=3, mode='regression', batch_size=20, random_seed=i, tensorboard=True) \n",
        "                         for i in range(self.ensemble_size)} #map each model to its seed\n",
        "        self.history = [] #save snapshot of model, on disk\n",
        "        self.samples_seen = None\n",
        "        self.smiles_seen = []\n",
        "        self.selected_prediction = pd.DataFrame()\n",
        "        self.all_predictions = {}\n",
        "        self.cost = 0\n",
        "        self.number_molecules = 0\n",
        "        self.time = 0 #days\n",
        "        \n",
        "        \n",
        "    def train_model(self, model, dataset):\n",
        "        \"\"\"Helper function to train a given ensemble model on a given dataset.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        model : Keras model (generally deepchem.GraphConvModel)\n",
        "            Model to be trained.\n",
        "        dataset : pandas.DataFrame\n",
        "            Dataset to train on. Must include \"SMILES\", \"bace\", \"esol\", and \"logD\" headers.\n",
        "            \n",
        "        \"\"\"\n",
        "        #convert DataFrame to CSV and read in as deepchem.Dataset via deepchem.CSVLoader\n",
        "        \n",
        "        dataset.to_csv(\"training_dataset.csv\")\n",
        "        \n",
        "        featurizer = dc.feat.ConvMolFeaturizer()\n",
        "        loader = dc.data.CSVLoader(tasks=[\"bace\", \"esol\", \"logD\"], smiles_field=\"SMILES\", featurizer=featurizer)\n",
        "\n",
        "        dataset_feat = loader.featurize(\"training_dataset.csv\")\n",
        "        \n",
        "        transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "        dataset_feat = transformer.transform(dataset_feat)\n",
        "\n",
        "        model.fit(dataset_feat, nb_epoch=self.epochs, deterministic=True, restore=False)\n",
        "    \n",
        "    \n",
        "    def train_ensemble(self, dataset):\n",
        "        \"\"\"Helper function to train model ensemble.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset : pandas.Dataset\n",
        "            Dataset on which to train models. Must include \"SMILES\", \"bace\", \"esol\", and \"logD\" headers.\n",
        "        \n",
        "        \"\"\"\n",
        "        for model in self.ensemble.values():\n",
        "            self.train_model(model, dataset)\n",
        "\n",
        "    \n",
        "    def initial_training(self, verbose=False):\n",
        "        \"\"\"Train model ensemble for the first time on self.N samples randomly chosen from the 2500 lowest bace affinity-scored \n",
        "        molecules.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        verbose : bool\n",
        "            Whether to print progress updates.\n",
        "        \n",
        "        Notes\n",
        "        -----\n",
        "        If self.N > 2500, ensemble will be trained on 2500 samples.\n",
        "        Records first history object.\n",
        "        \n",
        "        \"\"\"\n",
        "        idx_range = self.N if self.N < low_bace_dataset.shape[0] else low_bace_dataset.shape[0]\n",
        "        rand_indices = np.random.choice(range(low_bace_dataset.shape[0]), idx_range, replace=False) #select random row indices\n",
        "        \n",
        "        init_ensemble_dataset = pd.DataFrame()\n",
        "        for idx in rand_indices:\n",
        "            init_ensemble_dataset = init_ensemble_dataset.append( low_bace_dataset.iloc[idx], ignore_index=True )\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"Training set selected.\")\n",
        "            \n",
        "        self.samples_seen = init_ensemble_dataset ### collect the examples seen during initial training (ground truth values)\n",
        "        self.smiles_seen = init_ensemble_dataset[\"SMILES\"].tolist()\n",
        "        \n",
        "        #cost/time to initially train? free initial knowledge?\n",
        "        self.cost += self.molecule_cost * len(init_ensemble_dataset)\n",
        "        self.number_molecules += len(init_ensemble_dataset)\n",
        "        self.time = 0\n",
        "        \n",
        "\n",
        "        if self.sampling_method != \"random\":\n",
        "            if verbose:\n",
        "                print(\"Training ensemble...\")\n",
        "            self.train_ensemble(init_ensemble_dataset) #train ensemble on initial dataset, unless we are randomly sampling and do not need to        \n",
        "            if verbose:\n",
        "                print(\"Ensemble trained.\")\n",
        "                \n",
        "        self.record_history()\n",
        "\n",
        "                \n",
        "    def get_component_score(self, arr, keys):\n",
        "        \"\"\"Helper function to get the scaled \"goodness\" of the input scores.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        array : numpy.array\n",
        "             Array with bace, esol, and logD scores.\n",
        "        keys : collection of strings from {\"bace\", \"esol\", \"logD\"}\n",
        "            Which scores to incorporate into the overall goodness.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        numpy.array\n",
        "            Sum of component scores.\n",
        "        \n",
        "        \"\"\"\n",
        "        scores = []\n",
        "        if \"bace\" in keys:\n",
        "            #higher bace => higher score\n",
        "            bace = arr[:,0]\n",
        "            bace_range = self.target_bounds[\"bace\"]\n",
        "            scores.append( np.where(bace < bace_range[0], 0.2*bace-0.8, 0.05*bace-0.2) )\n",
        "            #dec penalty when score>low end of range\n",
        "        \n",
        "        if \"esol\" in keys:\n",
        "            esol = arr[:,1]\n",
        "            esol_range = self.target_bounds[\"esol\"]\n",
        "            scores.append( np.where(esol < esol_range[0], esol - np.absolute(esol-esol_range[1])**2, esol) )\n",
        "        \n",
        "        if \"logD\" in keys:\n",
        "            #logD within range is not penalized\n",
        "            logD = arr[:,2]\n",
        "            logD_range = self.target_bounds[\"logD\"]\n",
        "            #handle lower end of range\n",
        "            int_arr = np.where(logD < logD_range[0], logD - np.absolute(logD-logD_range[0]), logD)\n",
        "            #handle upper end of range\n",
        "            scores.append(np.where(int_arr > logD_range[1], int_arr - np.absolute(int_arr-logD_range[1]), int_arr) )\n",
        "\n",
        "        return sum(scores)\n",
        "        \n",
        "    \n",
        "    def score_and_select_top(self):\n",
        "        \"\"\"Scores all molecules and selects the top M for \"purchase\".\n",
        "        \n",
        "        \"\"\"\n",
        "        #featurizer = dc.feat.ConvMolFeaturizer()\n",
        "        #loader = dc.data.CSVLoader(tasks=[\"bace\", \"esol\", \"logD\"], smiles_field=\"SMILES\", featurizer=featurizer)\n",
        "        #dataset_feat = loader.featurize(dataset_file) #featurize the molecules from the ground truth dataset\n",
        "        #transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=dataset_feat)\n",
        "        #dataset_feat = transformer.transform(dataset_feat)\n",
        "        \n",
        "        if self.sampling_method == \"highest mean\":\n",
        "            #generate and store all predictions\n",
        "            predicted = np.zeros( (len(ground_truth_for_scoring),3) )\n",
        "            for key in self.ensemble.keys():\n",
        "                pred = self.ensemble[key].predict(ground_truth_for_scoring)\n",
        "                predicted += pred #sum model predictions\n",
        "                self.all_predictions[key] = self.prediction_array_to_dataframe(pred) #store each prediction as a labeled dataframe\n",
        "            predicted /= len(self.ensemble) #avg model predictions\n",
        "            results_df = self.prediction_array_to_dataframe(predicted)\n",
        "            \n",
        "        elif self.sampling_method == \"thompson\":\n",
        "            #generate and store all predictions\n",
        "            self.all_predictions = {key : self.prediction_array_to_dataframe( self.ensemble[key].predict(ground_truth_for_scoring) )\n",
        "                                    for key in self.ensemble.keys()} #store all labeled dataframes       \n",
        "            #Thompson sampling\n",
        "            results_df = pd.DataFrame()\n",
        "            for row_idx in range( len(ground_truth_for_scoring) ):\n",
        "                pred_key = np.random.randint(low=0, high=len(ground_truth_for_scoring)) #select one random prediction array to select a row from\n",
        "                pred_df = self.all_predictions[pred_key]\n",
        "                pred_row = pred_df.iloc[[row_idx]]\n",
        "                results_df = pd.concat([results_df, pred_row], sort=False)         \n",
        "        \n",
        "        elif self.sampling_method == \"random\":\n",
        "            ###randomly select up to M points from those not seen\n",
        "            unseen = ground_truth_dataset.loc[~ground_truth_dataset['SMILES'].isin(self.smiles_seen)] #remove prev seen\n",
        "            unseen = unseen.iloc[np.random.permutation(len(unseen))] #shuffle remaining samples\n",
        "            unseen = unseen[:self.M] if (len(unseen) > self.M) else unseen #select up to self.M samples\n",
        "            \n",
        "            self.samples_seen = pd.concat([self.samples_seen,unseen], sort=False)\n",
        "            self.smiles_seen = self.samples_seen[\"SMILES\"].tolist()\n",
        "            self.cost += self.molecule_cost * len(unseen)\n",
        "            self.number_molecules += len(unseen)\n",
        "            self.time += 28 #4 weeks to buy and experiment             \n",
        "            return \n",
        "            \n",
        "        self.selected_prediction = results_df #also store the dataframe with the data we chose to make decisions with\n",
        "        \n",
        "        unseen_predicted_rows = results_df.loc[~results_df['SMILES'].isin(self.smiles_seen)] #also remove predicted values previously seen\n",
        "        unseen_predicted_rows = unseen_predicted_rows.sort_values(by=\"goodness\", ascending=False) #sort predictions with highest goodness at top\n",
        "        \n",
        "        predicted_subset = unseen_predicted_rows[:self.M] if (len(unseen_predicted_rows) > self.M) else unseen_predicted_rows #select up to self.M samples from the predictions\n",
        "        predicted_subset_smiles = predicted_subset[\"SMILES\"].tolist()\n",
        "        \n",
        "        new_batch_ground_truth = ground_truth_dataset.loc[ground_truth_dataset['SMILES'].isin(predicted_subset_smiles)]\n",
        "        \n",
        "        self.samples_seen = pd.concat([self.samples_seen,new_batch_ground_truth], sort=False)\n",
        "        self.smiles_seen = self.samples_seen[\"SMILES\"].tolist()\n",
        "        self.cost += self.molecule_cost * len(new_batch_ground_truth)\n",
        "        self.number_molecules += len(new_batch_ground_truth)\n",
        "        self.time += 28 #4 weeks to buy and experiment\n",
        "    \n",
        "    \n",
        "    def prediction_array_to_dataframe(self, array):\n",
        "        #copy SMILES and assign calculated scores, store in self.predictions\n",
        "        df = pd.DataFrame()\n",
        "        df[\"SMILES\"] = ground_truth_dataset[\"SMILES\"]   \n",
        "        goodness = self.get_component_score(array, [\"bace\", \"esol\", \"logD\"])\n",
        "        df[\"bace\"] = array[:,0]\n",
        "        df[\"esol\"] = array[:,1]\n",
        "        df[\"logD\"] = array[:,2]\n",
        "        df[\"goodness\"] = goodness\n",
        "        return df\n",
        "        \n",
        "    \n",
        "    def record_history(self):\n",
        "        \"\"\"Stores model costs and experience for later analysis.\n",
        "        \n",
        "        Notes\n",
        "        -----\n",
        "        Does not save self.history attribute, in order to avoid redundantly storing the data in it.\n",
        "        Only saves attributes that change in each time step.\n",
        "        \n",
        "        \"\"\"\n",
        "        hist = {}\n",
        "        hist[\"samples_seen\"] = self.samples_seen\n",
        "        hist[\"smiles_seen\"] = self.smiles_seen\n",
        "        hist[\"cost\"] = self.cost\n",
        "        hist[\"number_molecules\"] = self.number_molecules\n",
        "        hist[\"time\"] = self.time\n",
        "        hist[\"selected_prediction\"] = self.selected_prediction\n",
        "        hist[\"all_predictions\"] = self.all_predictions\n",
        "        self.history.append(hist)\n",
        "     \n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Simple wrapper to automate calls to select molecules and update models. \n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        candidates : pandas.DataFrame\n",
        "            The candidate compounds that satisfy the given criteria.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Must be preceded by initial training of model ensemble.\n",
        "        \n",
        "        \"\"\"       \n",
        "        itr = 0\n",
        "        while len(self.samples_seen) < len(ground_truth_dataset): #search entire database, with early stopping\n",
        "            \n",
        "            #THE BELOW LINES STRICTLY ENFORCE THE PROPERTY RANGES DEFINED ABOVE, \n",
        "            #candidates = self.samples_seen.loc[self.samples_seen['bace'] >= top_5_percent_bace_cutoff] #find mols w/ high bace\n",
        "            \n",
        "            #esol_lower_bound = self.target_bounds[\"esol\"][0]\n",
        "            #candidates = candidates.loc[candidates['esol'] >= esol_lower_bound] #filter the insoluble mols\n",
        "            \n",
        "            #logD_range = self.target_bounds[\"logD\"]\n",
        "            #candidates = candidates.loc[( candidates['logD'] >= logD_range[0] ) \n",
        "            #                                     & ( candidates['logD'] <= logD_range[1] )] #filter for logD in range\n",
        "              \n",
        "            #if len(candidates) > 0:\n",
        "            #    print(\"Molecule within bounds and 95th percentile bace affinity found.\")\n",
        "            #   return candidates\n",
        "                \n",
        "            self.score_and_select_top()\n",
        "            self.record_history()\n",
        "            print(\"PROGRESS:\",len(self.samples_seen),\"of\",len(ground_truth_dataset))\n",
        "            if self.sampling_method != \"random\":\n",
        "                self.train_ensemble(self.samples_seen)\n",
        "                \n",
        "            with open(\"drive/My Drive/models/mean_model_\"+str(itr)+\".pickle\", \"wb\") as f:\n",
        "                pickle.dump(self.history,f)\n",
        "            itr += 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVz_6D1WkrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### ADD %%prun command to cell below to run and time with profiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YVdK0hJ1wmB",
        "colab_type": "code",
        "outputId": "f854f6e2-55d2-4a87-9160-06dc21629540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%prun\n",
        "#N = [96, 384, 1536] #initial train set size\n",
        "N = [384]\n",
        "#M = [96, 384, 1536] #batch size -> 96 wells, multiples\n",
        "M = [384]\n",
        "\n",
        "model_hxs = []\n",
        "\n",
        "for n in N:\n",
        "    for m in M:\n",
        "        for i in range(5):\n",
        "            print(\"\\n\",\"Iteration:\",i,\"\\n\")\n",
        "            mean_model = Experimenter(n, m, ensemble_size=2, epochs=3, sampling_method='highest mean')\n",
        "            mean_model.initial_training()\n",
        "            mean_model.run()\n",
        "            model_hxs.append(mean_model.history)\n",
        "            break\n",
        "        \n",
        "        print(\"Mean models trained, and in dict/list.\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Iteration: 0 \n",
            "\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 1.333 s\n",
            "TIMING: dataset construction took 1.484 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.190 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 60: Average loss 0.6664\n",
            "TIMING: model fitting took 21.060 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 1.371 s\n",
            "TIMING: dataset construction took 1.518 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.182 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ending global_step 60: Average loss 0.729455\n",
            "TIMING: model fitting took 21.629 s\n",
            "PROGRESS: 768 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 2.804 s\n",
            "TIMING: dataset construction took 3.102 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.405 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 177: Average loss 0.656883\n",
            "TIMING: model fitting took 7.911 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 2.765 s\n",
            "TIMING: dataset construction took 3.068 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.384 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 177: Average loss 0.649562\n",
            "TIMING: model fitting took 9.159 s\n",
            "PROGRESS: 1152 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 4.339 s\n",
            "TIMING: dataset construction took 4.822 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.612 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 351: Average loss 0.810169\n",
            "TIMING: model fitting took 8.120 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 4.409 s\n",
            "TIMING: dataset construction took 4.891 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.621 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 351: Average loss 0.726953\n",
            "TIMING: model fitting took 9.918 s\n",
            "PROGRESS: 1536 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 5.761 s\n",
            "TIMING: dataset construction took 6.374 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.839 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 582: Average loss 0.638994\n",
            "TIMING: model fitting took 10.606 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 5.815 s\n",
            "TIMING: dataset construction took 6.436 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.829 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 582: Average loss 0.550049\n",
            "TIMING: model fitting took 11.280 s\n",
            "PROGRESS: 1920 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 7.254 s\n",
            "TIMING: dataset construction took 8.046 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.660 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 870: Average loss 0.574812\n",
            "TIMING: model fitting took 12.156 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 7.311 s\n",
            "TIMING: dataset construction took 8.128 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.055 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 870: Average loss 0.511441\n",
            "TIMING: model fitting took 13.969 s\n",
            "PROGRESS: 2304 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "TIMING: featurizing shard 0 took 8.743 s\n",
            "TIMING: dataset construction took 9.695 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.257 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 999: Average loss 0.465452\n",
            "Ending global_step 1218: Average loss 0.410883\n",
            "TIMING: model fitting took 14.262 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "TIMING: featurizing shard 0 took 8.704 s\n",
            "TIMING: dataset construction took 9.652 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.267 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 999: Average loss 0.460979\n",
            "Ending global_step 1218: Average loss 0.417084\n",
            "TIMING: model fitting took 15.548 s\n",
            "PROGRESS: 2688 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "TIMING: featurizing shard 0 took 10.116 s\n",
            "TIMING: dataset construction took 11.248 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.549 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 1623: Average loss 0.334594\n",
            "TIMING: model fitting took 16.882 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "TIMING: featurizing shard 0 took 10.161 s\n",
            "TIMING: dataset construction took 11.297 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.094 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 1623: Average loss 0.345263\n",
            "TIMING: model fitting took 17.464 s\n",
            "PROGRESS: 3072 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "TIMING: featurizing shard 0 took 12.012 s\n",
            "TIMING: dataset construction took 13.315 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.730 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 1999: Average loss 0.2762\n",
            "Ending global_step 2085: Average loss 0.273114\n",
            "TIMING: model fitting took 18.837 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "TIMING: featurizing shard 0 took 11.667 s\n",
            "TIMING: dataset construction took 12.953 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.355 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 1999: Average loss 0.282124\n",
            "Ending global_step 2085: Average loss 0.272184\n",
            "TIMING: model fitting took 19.623 s\n",
            "PROGRESS: 3456 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "TIMING: featurizing shard 0 took 13.133 s\n",
            "TIMING: dataset construction took 14.563 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.926 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 2604: Average loss 0.235914\n",
            "TIMING: model fitting took 20.813 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "TIMING: featurizing shard 0 took 13.136 s\n",
            "TIMING: dataset construction took 14.547 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 1.905 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 2604: Average loss 0.240069\n",
            "TIMING: model fitting took 22.017 s\n",
            "PROGRESS: 3840 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "TIMING: featurizing shard 0 took 14.478 s\n",
            "TIMING: dataset construction took 16.119 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.176 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 2999: Average loss 0.208294\n",
            "Ending global_step 3180: Average loss 0.193327\n",
            "TIMING: model fitting took 22.782 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "TIMING: featurizing shard 0 took 14.664 s\n",
            "TIMING: dataset construction took 16.280 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.218 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 2999: Average loss 0.212041\n",
            "Ending global_step 3180: Average loss 0.192537\n",
            "TIMING: model fitting took 24.170 s\n",
            "PROGRESS: 4224 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "TIMING: featurizing shard 0 took 16.002 s\n",
            "TIMING: dataset construction took 17.769 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.375 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 3816: Average loss 0.184747\n",
            "TIMING: model fitting took 24.711 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "TIMING: featurizing shard 0 took 16.064 s\n",
            "TIMING: dataset construction took 17.856 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.366 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 3816: Average loss 0.182436\n",
            "TIMING: model fitting took 26.018 s\n",
            "PROGRESS: 4608 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "TIMING: featurizing shard 0 took 18.105 s\n",
            "TIMING: dataset construction took 20.025 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.599 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 3999: Average loss 0.165629\n",
            "Ending global_step 4509: Average loss 0.176495\n",
            "TIMING: model fitting took 26.954 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "TIMING: featurizing shard 0 took 17.990 s\n",
            "TIMING: dataset construction took 19.927 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.619 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 3999: Average loss 0.159129\n",
            "Ending global_step 4509: Average loss 0.169666\n",
            "TIMING: model fitting took 28.295 s\n",
            "PROGRESS: 4992 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "TIMING: featurizing shard 0 took 18.952 s\n",
            "TIMING: dataset construction took 20.997 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.421 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 4999: Average loss 0.15559\n",
            "Ending global_step 5259: Average loss 0.144376\n",
            "TIMING: model fitting took 28.996 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "TIMING: featurizing shard 0 took 19.024 s\n",
            "TIMING: dataset construction took 21.076 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 2.808 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 4999: Average loss 0.155986\n",
            "Ending global_step 5259: Average loss 0.146665\n",
            "TIMING: model fitting took 30.301 s\n",
            "PROGRESS: 5376 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "TIMING: featurizing shard 0 took 20.434 s\n",
            "TIMING: dataset construction took 22.815 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.142 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 5999: Average loss 0.135876\n",
            "Ending global_step 6066: Average loss 0.15098\n",
            "TIMING: model fitting took 31.480 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "TIMING: featurizing shard 0 took 20.436 s\n",
            "TIMING: dataset construction took 22.757 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.688 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 5999: Average loss 0.139845\n",
            "Ending global_step 6066: Average loss 0.153427\n",
            "TIMING: model fitting took 32.203 s\n",
            "PROGRESS: 5760 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "TIMING: featurizing shard 0 took 22.051 s\n",
            "TIMING: dataset construction took 24.507 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.384 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 6930: Average loss 0.129802\n",
            "TIMING: model fitting took 33.320 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "TIMING: featurizing shard 0 took 21.963 s\n",
            "TIMING: dataset construction took 24.486 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.307 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 6930: Average loss 0.132054\n",
            "TIMING: model fitting took 33.969 s\n",
            "PROGRESS: 6144 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "TIMING: featurizing shard 0 took 23.478 s\n",
            "TIMING: dataset construction took 26.108 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.509 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 6999: Average loss 0.113852\n",
            "Ending global_step 7854: Average loss 0.122398\n",
            "TIMING: model fitting took 35.365 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "TIMING: featurizing shard 0 took 23.284 s\n",
            "TIMING: dataset construction took 25.912 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.143 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 6999: Average loss 0.118025\n",
            "Ending global_step 7854: Average loss 0.125024\n",
            "TIMING: model fitting took 36.099 s\n",
            "PROGRESS: 6528 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "TIMING: featurizing shard 0 took 24.837 s\n",
            "TIMING: dataset construction took 27.615 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.809 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 7999: Average loss 0.106283\n",
            "Ending global_step 8835: Average loss 0.116077\n",
            "TIMING: model fitting took 37.142 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "TIMING: featurizing shard 0 took 25.630 s\n",
            "TIMING: dataset construction took 28.409 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.327 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 7999: Average loss 0.1106\n",
            "Ending global_step 8835: Average loss 0.121487\n",
            "TIMING: model fitting took 38.370 s\n",
            "PROGRESS: 6912 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "TIMING: featurizing shard 0 took 26.332 s\n",
            "TIMING: dataset construction took 29.264 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 3.985 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 8999: Average loss 0.100472\n",
            "Ending global_step 9873: Average loss 0.117139\n",
            "TIMING: model fitting took 39.472 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "TIMING: featurizing shard 0 took 26.210 s\n",
            "TIMING: dataset construction took 29.137 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.554 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 8999: Average loss 0.105485\n",
            "Ending global_step 9873: Average loss 0.1184\n",
            "TIMING: model fitting took 41.111 s\n",
            "PROGRESS: 7296 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "TIMING: featurizing shard 0 took 27.882 s\n",
            "TIMING: dataset construction took 30.964 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.160 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 9999: Average loss 0.100545\n",
            "Ending global_step 10968: Average loss 0.110008\n",
            "TIMING: model fitting took 41.505 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "TIMING: featurizing shard 0 took 27.719 s\n",
            "TIMING: dataset construction took 30.792 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.227 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 9999: Average loss 0.0973686\n",
            "Ending global_step 10968: Average loss 0.110908\n",
            "TIMING: model fitting took 42.912 s\n",
            "PROGRESS: 7680 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "TIMING: featurizing shard 0 took 29.308 s\n",
            "TIMING: dataset construction took 32.524 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.321 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 10999: Average loss 0.0964035\n",
            "Ending global_step 11999: Average loss 0.101276\n",
            "Ending global_step 12120: Average loss 0.116746\n",
            "TIMING: model fitting took 43.313 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "TIMING: featurizing shard 0 took 29.219 s\n",
            "TIMING: dataset construction took 32.479 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.437 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 10999: Average loss 0.0937968\n",
            "Ending global_step 11999: Average loss 0.104211\n",
            "Ending global_step 12120: Average loss 0.11928\n",
            "TIMING: model fitting took 45.126 s\n",
            "PROGRESS: 8064 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 30.855 s\n",
            "TIMING: dataset construction took 34.359 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.752 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 12999: Average loss 0.0999043\n",
            "Ending global_step 13332: Average loss 0.095308\n",
            "TIMING: model fitting took 46.065 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 30.582 s\n",
            "TIMING: dataset construction took 34.001 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.591 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 12999: Average loss 0.100765\n",
            "Ending global_step 13332: Average loss 0.098223\n",
            "TIMING: model fitting took 47.254 s\n",
            "PROGRESS: 8448 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.490 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 1 took 0.951 s\n",
            "TIMING: dataset construction took 36.215 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.646 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 13999: Average loss 0.0941975\n",
            "Ending global_step 14601: Average loss 0.0966271\n",
            "TIMING: model fitting took 47.914 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 30.938 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 1 took 0.938 s\n",
            "TIMING: dataset construction took 35.616 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 4.994 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 13999: Average loss 0.0945634\n",
            "Ending global_step 14601: Average loss 0.0987372\n",
            "TIMING: model fitting took 49.220 s\n",
            "PROGRESS: 8832 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.124 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 1 took 2.355 s\n",
            "TIMING: dataset construction took 37.325 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.172 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 14999: Average loss 0.0856149\n",
            "Ending global_step 15927: Average loss 0.0938525\n",
            "TIMING: model fitting took 49.552 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.843 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 1 took 2.356 s\n",
            "TIMING: dataset construction took 38.125 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.282 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 14999: Average loss 0.0882678\n",
            "Ending global_step 15927: Average loss 0.0929036\n",
            "TIMING: model fitting took 50.941 s\n",
            "PROGRESS: 9216 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.020 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 3.764 s\n",
            "TIMING: dataset construction took 38.757 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.426 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15999: Average loss 0.0818733\n",
            "Ending global_step 16999: Average loss 0.0891978\n",
            "Ending global_step 17310: Average loss 0.0867097\n",
            "TIMING: model fitting took 51.781 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.364 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 3.734 s\n",
            "TIMING: dataset construction took 39.063 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.927 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 15999: Average loss 0.0839356\n",
            "Ending global_step 16999: Average loss 0.0868\n",
            "Ending global_step 17310: Average loss 0.0858869\n",
            "TIMING: model fitting took 52.549 s\n",
            "PROGRESS: 9600 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.174 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 5.349 s\n",
            "TIMING: dataset construction took 40.679 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.644 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 17999: Average loss 0.0856196\n",
            "Ending global_step 18750: Average loss 0.0875683\n",
            "TIMING: model fitting took 54.118 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.957 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 5.219 s\n",
            "TIMING: dataset construction took 41.335 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.666 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 17999: Average loss 0.0823952\n",
            "Ending global_step 18750: Average loss 0.0849508\n",
            "TIMING: model fitting took 55.415 s\n",
            "PROGRESS: 9984 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.379 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 6.685 s\n",
            "TIMING: dataset construction took 42.368 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.889 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 18999: Average loss 0.0751247\n",
            "Ending global_step 19999: Average loss 0.0847093\n",
            "Ending global_step 20250: Average loss 0.088277\n",
            "TIMING: model fitting took 56.480 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.415 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 6.724 s\n",
            "TIMING: dataset construction took 42.470 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.845 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 18999: Average loss 0.0729841\n",
            "Ending global_step 19999: Average loss 0.0833378\n",
            "Ending global_step 20250: Average loss 0.0870806\n",
            "TIMING: model fitting took 57.335 s\n",
            "PROGRESS: 10000 of 10000\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.422 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 6.768 s\n",
            "TIMING: dataset construction took 42.581 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.878 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 20999: Average loss 0.0770071\n",
            "Ending global_step 21750: Average loss 0.0777564\n",
            "TIMING: model fitting took 56.052 s\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from training_dataset.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "Featurizing sample 2000\n",
            "Featurizing sample 3000\n",
            "Featurizing sample 4000\n",
            "Featurizing sample 5000\n",
            "Featurizing sample 6000\n",
            "Featurizing sample 7000\n",
            "Featurizing sample 8000\n",
            "TIMING: featurizing shard 0 took 31.862 s\n",
            "Loading shard 2 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 1 took 6.764 s\n",
            "TIMING: dataset construction took 43.014 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 5.872 s\n",
            "Loading dataset from disk.\n",
            "Ending global_step 20999: Average loss 0.0769632\n",
            "Ending global_step 21750: Average loss 0.0771851\n",
            "TIMING: model fitting took 56.891 s\n",
            "Mean models trained, and in dict/list.\n",
            "\n",
            " "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_K7E9QqRMer",
        "colab_type": "code",
        "outputId": "10559bcb-5a87-4f2d-ce3d-c768c403cdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "top_mols\n",
        "print(e.history[1][\"number_molecules\"])\n",
        "\n",
        "baces = np.array(e.history[1][\"samples_seen\"][\"bace\"])\n",
        "#plt.hist(baces, 50, facecolor='green')\n",
        "\n",
        "import seaborn as sns\n",
        "sns.kdeplot(baces,shade=True)\n",
        "plt.hist(baces, density=True)\n",
        "plt.show()\n",
        "\n",
        "#plt.xlabel('baces')\n",
        "#plt.ylabel('Number of compounds')\n",
        "#plt.title(r'Histogram of top mol bace scores')\n",
        "#plt.grid(True)\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncjfGmCT0v0Zu98230VkIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElzKdt-s1wmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "    costs = []\n",
        "    times = []\n",
        "    top_gt_bace_scores = []\n",
        "    goodnesses = []\n",
        "    \n",
        "    for hx in model.history:\n",
        "        costs.append(hx[\"cost\"])\n",
        "        times.append(hx[\"time\"])\n",
        "        top_gt_bace_scores.append(hx[\"samples_seen\"][\"bace\"].max()) #max ground truth score seen\n",
        "        if hx[\"selected_prediction\"].empty:\n",
        "            goodnesses.append(0)\n",
        "        else:\n",
        "            goodnesses.append( hx[\"selected_prediction\"][\"goodness\"].max() ) #max predicted goodness so far\n",
        "\n",
        "plt.plot(times,top_gt_bace_scores,'bs',label=\"top ground truth bace seen\")\n",
        "plt.plot(times,goodnesses,'rs',label=\"top pred goodness\")\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.title(r'Time vs top ground truth BACE score seen so far')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqfW8LDlqFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gt_bace = ground_truth_dataset[\"bace\"].tolist()\n",
        "low_bace = low_bace_dataset[\"bace\"].tolist()\n",
        "\n",
        "x = [i for i in range(len(gt_bace))]\n",
        "print(min(gt_bace))\n",
        "print(gt_bace[-1])\n",
        "\n",
        "plt.clf()\n",
        "plt.xlim([0,10000])\n",
        "plt.ylim([2.5,5.6])\n",
        "\n",
        "plt.plot(x,gt_bace,'bs',label=\"ground truth bace\")\n",
        "plt.plot(x[:2500],low_bace,'gs',label=\"low bace set\")\n",
        "\n",
        "plt.xlabel('index')\n",
        "plt.title(r'bace of gt dataset')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvGri4ovDGoz",
        "colab_type": "code",
        "outputId": "e107089a-0250-4cb7-a855-8a2627883923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "#take map of dfs\n",
        "pred_map = e.history[-1][\"all_predictions\"] #get predictions from latest history\n",
        "#print(pred_map)\n",
        "\n",
        "#average their scores\n",
        "cat_df = pd.DataFrame()\n",
        "for pred in pred_map.values():\n",
        "    cat_df = pd.concat([cat_df, pred], sort=False)\n",
        "avgs = cat_df.groupby(\"SMILES\",as_index=False).mean()\n",
        "\n",
        "#have one set of mean data, one set of ground truth\n",
        "pred_bace = avgs.sort_values(by=\"SMILES\")[\"bace\"].tolist()\n",
        "act_bace = ground_truth_dataset.sort_values(by=\"SMILES\")[\"bace\"].tolist()\n",
        "\n",
        "#plot baces\n",
        "plt.scatter(pred_bace,act_bace)\n",
        "plt.xlabel(\"Predicted BACE pIC50\")\n",
        "plt.ylabel(\"Ground truth BACE pIC50\")\n",
        "plt.plot([-2,6], [-2,6], color='k')por\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX+//HXB0TFAljQVUBBLBBC\nNYKAroIINpDFui5fCyFBBGkKwg9XRFykCKJIJywqSpWOgFTpJSTUoICISlCJ0pQaks/vj7lhIyaT\ngczMnZl8no/HPJy5c+feNwHzmXPOPeeKqmKMMcYUcjuAMcaY0GAFwRhjDGAFwRhjjMMKgjHGGMAK\ngjHGGIcVBGOMMYAVBGOMMQ4rCMYYYwArCMYYYxwXuB3gXFx99dVatmxZt2MYY0xY2bBhw6+qWjKv\n/cKqIJQtW5bExES3YxhjTFgRke992c+6jIwxxgBWEIwxxjisIBhjjAGsIBhjjHFYQTDGGAO4XBBE\npISITBGRr0Vku4jUdjOPMcYUZG5fdvo+ME9VHxeRC4FLXM5jjDEFlmstBBEpDvwdSABQ1VOqesit\nPMYYE4p+++03OnTowOHDhwN+Lje7jMoBacB/RSRZREaLyKVn7yQi8SKSKCKJaWlpwU9pjDEuUFUm\nT55MVFQUQ4YMYdmyZQE/p5sF4QKgBjBMVasDR4GuZ++kqiNVNUZVY0qWzHPmtTHGhL2ffvqJZs2a\n8eSTT1KmTBk2bNhA48aNA35eNwvCXmCvqq51Xk/BUyCMMaZAUlXGjBlDxYoVmTdvHv369WPNmjVU\nqVIlKOd3rSCo6s/AjyJym7PpPiDFrTzGGOOm3bt3c//99xMbG0vVqlXZvHkznTt35oILgnftj9tX\nGb0MfOpcYbQbeMHlPMYYE1QZGRkMHjyY7t27U7hwYYYNG0Z8fDyFCgX/+7qrBUFVNwIxbmYwxhi3\npKSkEBsby5o1a3jooYcYPnw4ZcqUcS2PzVQ2xpggO3XqFL169aJ69ers3LmTcePGMXv2bFeLAbjf\nZWSMMQVKYmIisbGxbN68maeffpr333+fa665xu1YgLUQjDEmKI4dO0aXLl2oVasWv/76KzNmzGD8\n+PEhUwzAWgjGGBNwX331FS1btmTXrl3ExcXRv39/ihcv7nasv7CCYP5ienIq/ed/w75Dx7m+RFHq\nVSjJkq/Tzrzu3Og2mlYv5XZMY0LekSNHeO211xg+fDg33XQTixYton79+m7HypUVBPMn05NT6TZ1\nC8fTMwBIPXSccWt+OPN+6qHjdJu6BcCKgjFezJkzhxdffJF9+/bRqVMnevXqxSWXhPb6nTaGYP6k\n//xvzhSD3BxPz6D//G+ClMiY8PLrr7/SvHlzHnnkEYoXL86qVasYMGBAyBcDsIJgHNOTU6nbZzGp\nh477tP8+H/czpqBQVSZMmEDFihWZNGkSb775JklJSdSqVcvtaD6zLiPD9ORUOk/eRHqm+vyZ60sU\nDWAiY8JLamoqrVu3ZtasWdSsWZOEhASio6PdjnXOrCBEqLMHhs8eCJ6enErPWds4eCz9vI5f9ior\nCMaoKqNHj+bVV18lPT2dAQMG0L59ewoXLux2tPNiXUYRKGtgOPXQcZT/DQRPT04F4PXpW+gwceN5\nFwOAld8e4PXpW/yU2Jjw8+2333LfffcRHx/P7bffzpYtW+jUqVPYFgOwghCRchoYzhoInp6c+qer\nhvJj/Nof/XIcY8JJRkYGAwcOpHLlymzYsIGRI0eyaNEiypcv73a0fLMuowiU24Bv6qHjdJi40W/n\nyVDfxxyMiQRbt24lNjaWdevW0bhxY4YNG0apUpFz+bW1ECJQMAd8b+o650xXlDGR6tSpU7z55pvU\nqFGD7777jgkTJjBjxoyIKgZgBSEidW50G0WLBKcfMxPoMHGjjSeYiLVu3Tpq1KhBz549efLJJ0lJ\nSeGpp55CRNyO5neuFgQR2SMiW0Rko4gkupklkjStXop3mlWmRNEiQTvnuDU/WEvBRJRjx47xyiuv\nULt2bQ4fPszs2bMZN24cV199tdvRAiYUWgj1VLWaqtqNcvyoafVSXHpRcIeI/t/UzUE9nzGBsmTJ\nEipXrszAgQOJj49n27ZtPPzww27HCrhQKAgmQII9m/hYeqZ1HZmwdvjwYeLj46lfvz6FChVi6dKl\nDBs2jGLFirkdLSjcLggKfCkiG0Qk3uUsESNrGQo3rgGyriMTrmbOnElUVBQJCQl07tyZTZs2cc89\n97gdK6jcLgh3qWoN4EGgjYj8/ewdRCReRBJFJDEtLS34CcNM9klpbuk5a5tr5zbmXO3fv5+nn36a\nRx99lKuuuoq1a9fSr1+/sFiMzt9cLQiqmur8dz8wDaiZwz4jVTVGVWNKliwZ7Ihhx5fVSgMtPzOg\njQkWVeXTTz8lKiqKadOm0atXLxITE4mJKbjDma4VBBG5VEQuz3oONAS2upUnUtgqpMbk7ccff6Rx\n48Y0b96cW265heTkZF5//XUuvPBCt6O5ys0WwrXAChHZBKwD5qjqPBfzRITiQbzUNDfBvNzVmHOR\nmZnJ8OHDqVSpEkuWLGHQoEGsWLGCqKgot6OFBNeWrlDV3UBVt84fqdIzMt2OwJtNKrkdwZi/2Llz\nJ3FxcXz11Vc0aNCAkSNHUq5cObdjhRS3B5WNH01PTuXoKXfHD8BurWlCy+nTp+nfvz9VqlRh48aN\nJCQk8OWXX1oxyIEtbhchpien0smPC9edr8IROJ3fhK9NmzYRGxvLhg0baNq0KUOGDOH66693O1bI\nshZChHhz5jbc7yyCm0oWvEv1TOg5efIk//73v4mJieHHH39k0qRJTJ061YpBHqwgRIhDx0PjUs+d\n+4/abGXjqtWrV1O9enXefvttnnnmGVJSUnjiiScicjE6f7OCYPzOZisbNxw9epQOHTpQt25d/vjj\nD7744gs++ugjrrrqKrejhQ0bQ4gAofjLt9tUTyvBBphNMCxcuJC4uDj27NlDmzZteOedd7j88svd\njhV2rCCEoenJqfSf/w37Dh3n+hJFOXTslNuR/iLrlp1WEEwgHTx4kFdffZUxY8Zw6623smzZMu6+\n+263Y4UtKwhhJmutoqzlKdxcsygvNmvaBNK0adN46aWXSEtLo2vXrvTo0YOLL77Y7VhhLdeCICIX\nALHAP4CsoflUYAaQoKqhMYpZwITCWkW+CuatPE3B8csvv/Dyyy8zefJkqlWrxpw5c6hRo4bbsSKC\ntxbCJ8Ah4E1gr7OtNPAcMA54KqDJTI7C5Vt30SKF6dzoNrdjmAiiqnzyySd06NCBo0eP8p///IfO\nnTtTpIgtleIv3grC7ap661nb9gJrRGRHADMZL64vUTSku4kAihYpxDvNKtv4gfGbH374gVatWjFv\n3jzq1KlDQkICFSpUcDtWxPF22ekBEXlCRM7sIyKFROQp4GDgo5mcdG50G0WLFHY7hlcn0kNhipyJ\nBJmZmQwZMoRKlSqxfPlyBg8ezPLly60YBIi3gvA08Djwi4jsEJGdwM9AM+c944Km1UvxTrPKlArh\n/nnFM9ZhTH5888033HPPPbRt25Y6deqwdetW2rZtS6FCNn0qUHLtMlLVPTjjBCJylbPtt+DEMt40\nrV7qTHdM2a5zXE6Ts1Dv1jKhKz09nQEDBvDmm29yySWXMHbsWJ599lmbaRwEPl12qqq/iUg5EbkH\nSFHVrwOcy+Qhay5CqCpk/++a85CcnExsbCzJyck89thjfPjhh/ztb39zO1aBkWvbS0SmZ3v+KLAY\naAzMFJHnAx/N5CYU7pucl0wNzRnUJjSdOHGC7t27c8cdd7Bv3z6mTJnClClTrBgEmbfOuBuzPX8N\nqK+qLwB1gI7+CiAihUUkWURm++uYkS5c5iKEcgvGhI6VK1dSrVo1evfuzf/93/+RkpLCY4895nas\nAslbQdBszy9Q1e8AVPVX8OtKy+2B7X48XsQLl7kI4ZLTuOP333/n5Zdf5u677+bEiRPMnz+f//73\nv1x55ZVuRyuwvBWEqiJyRER+B6qJyHUAInIh4JfrHkWkNPAwMNofxysowmUGcLjkNME3f/58oqOj\nGTJkCC+//DJbt26lYcOGbscq8HItCKpaWFWLqerlqnqhqv7kvHUJ0MpP5x8EdMG/LY6IFw4zgIsU\nlrDIaYLrwIEDPP/88zzwwANccsklLF++nPfff5/LLrvM7WgG74PKN4tI3Rzeigb25/fEIvIIsF9V\nN+SxX7yIJIpIYlpaWn5PGxGaVi9FyF/Eo3nvYgqWzz//nKioKMaNG0f37t1JTk6mbt2cfsUYt3jr\nMhoEHMlh+2HnvfyqCzQRkT3ABKC+iIw7eydVHamqMaoaU7JkST+cNjLUKR/a/azpmWqDygaAn376\niccee4zHH3+c66+/nsTERN5++21bmTQEeSsI16rqX+6F6Gwrm98Tq2o3VS2tqmXxzHxerKrN83vc\nguD16VtY9e0Bt2PkyQaVCzZVZezYsURFRTFnzhz69OnDunXrqFatmtvRTC68TUwr4eU9Gy10yfTk\nVD5d80NY9MjYoHLBtWfPHuLj41mwYAF33303o0eP5tZbz14r04Qaby2ERBGJO3ujiLQEvPb7nytV\nXaqqj/jzmJFoenIqr0zaFBbFwJa/LpgyMjL44IMPiI6OZvXq1QwZMoSlS5daMQgT3loIHYBpIvIv\n/lcAYoAL8dw0xwRR1uzkDA3dclBIQNXTMujc6DZb/rqA2b59Oy1btmTVqlU88MADjBgxghtuuMHt\nWOYceFvc7hegjojUw3NlEcAcVV0clGTmT8JhdrIqfNfnYbdjmCBLT0+nX79+vPXWW1x22WV8/PHH\nNG/e3BajC0PebqGZdRnLJufxp+2qGvqjmhEkHAZoixaxZYkLmqSkJFq0aMGmTZt48skn+eCDD7j2\n2mvdjmXOk7cuow14ribPqcwrcFNAEpkclbikCAePhfZtrI+lZzI9OdW6igqA48eP07NnT959912u\nueYapk2bRtOmTd2OZfLJW5dRuWAGMd6F8NDBn/Sf/40VhAi3bNkyWrZsyc6dO4mNjeXdd9+lRAlv\nFyWacOHT/RBEpBlwF56WwXJVnZ7HR4yfHToe2q2DLOHQtWXOz5EjR+jWrRtDhw6lXLlyLFy4kPvu\nu8/tWMaP8uz0FZGhwIvAFmAr8KKIDAl0MPNnhcNkgM7mHkSmuXPnEh0dzbBhw+jQoQNbtmyxYhCB\nfGkh1Acqqno6LUTkI2BbQFOZvwjly02z2NyDyPPbb7/RsWNHPvnkE6Kioli1ahV33nmn27FMgPhy\nWcguIPvFxGWcbSaISoXoN+9SJYoizn/faVbZxg8ihKoyadIkKlasyPjx4/n3v/9NUlKSFYMI50sL\n4XJgu4iswzOGUBPPLOaZAKraJID5jKNzo9voNnVLSM1FKFWiKCu71nc7hvGzffv28dJLLzFjxgxi\nYmJYuHAhVapUcTuWCQJfCsIbAU9h8pT1zbvnrG0hcfmpdQ9FHlVlzJgxvPLKK5w8eZL+/fvToUMH\nLrjAp2tPTATI829aVb8KRhDjmxPpoXEvoePpGWeWt7ZuovC3e/du4uLiWLx4Mffccw+jR4/m5ptv\ndjuWCTKbWhpGQm35itRDx+k2dQvTk1PdjmLOU0ZGBoMGDaJy5cqsX7+e4cOHs3jxYisGBZQVhDAS\nitf4Z28pmPCybds26tatS8eOHalXrx4pKSm0atWKQoXs10JB5e0WmsW8vGdLGLogVK/xD8VCZXJ3\n6tQp3nrrLapXr86uXbv49NNPmTVrFqVLl3Y7mnGZt68CS7OeiMiis96zmcouqFchNG8hGqqFyvzV\n+vXriYmJoUePHjz++ONs376dZ555xlYmNYD3gpD9X8jZN/DN978eEblYRNaJyCYR2SYiPfN7zEi3\n5Os0tyP85S/erjYKD8eOHaNz587ceeedHDhwgJkzZ/LZZ59h9yk32Xm7ykhzeZ7T6/NxEqivqn+I\nSBFghYjMVdU1fjh2RAqFrpk65a9kz2/H2XfouN0IJ0wsXbqUuLg4du3aRXx8PP369aN48eJuxzIh\nyFtBuEZEOuH5Upj1HOd1vr9WOEth/OG8LOI8Qn99BhddX6IoqS4XhT2/HbfJaGHi8OHDvPbaa4wY\nMYLy5cuzePFi6tWr53YsE8K8dRmNwjNL+bJsz7Nej/bHyUWksIhsBPYDC1R1bQ77xItIoogkpqW5\n32XiplAYQwiFVorJ2+zZs6lUqRKjRo3ilVdeYfPmzVYMTJ683Q8h4H36qpoBVBOREnju3xytqlvP\n2mckMBIgJiamQLcgQmEMwQaQQ1taWhrt27dn/PjxREdHM3XqVGrWrOl2LBMmvF122l9EWuWwvZWI\n9PFnCFU9BCwBHvDncSON29/ObQA5dKkq48ePJyoqiilTptCzZ082bNhgxcCcE29dRvVxvpmfZRTw\nSH5PLCIlnZYBIlIUuB/4Or/HjWRufDu31UxD3969e2nSpAnPPPMMN910E0lJSbzxxhtceOGFbkcz\nYcbboPJFWfdAyE5VM8U/Fy1fB3wkIoXxFKZJqjrbD8eNWMFe8bSwiA0gh7DMzExGjx5N586dSU9P\nZ+DAgbRr147ChQu7Hc2EKW8F4biI3KKqO7NvFJFbgHz3XajqZqB6fo9TkGR9O+8//xtSDx1HCOxl\nWeFwU56CateuXcTFxbF06VLq1avHqFGjKF++vNuxTJjz1mX0BjBXRJ4XkcrO4wVgDrYktmuaVi/F\nyq71KVWiaMCv0S0sYgvXhZjTp08zYMAAqlSpQlJSEqNGjWLRokVWDIxfeLvKaK6INAU6Ay87m7cB\nj6nqlmCEM382PTn1TOsgGDJU6TbV81dtYwfu27JlC7Gxsaxfv54mTZowdOhQSpWyvxfjP16XNVTV\nrar6nKre7jyeBXaKyBNBymcc05NT6TZ1S9Anptlqpu47efIkPXr0oEaNGuzZs4cJEyYwffp0KwbG\n73xa59aZQPaQiHwCfA88FdhY5my+3gshEEuUuX25a0G2du1abr/9dt566y2efvppUlJSeOqpp2wx\nOhMQXguCiNwjIiOAPUAsnktDy6nq40HIZrLx9Zfye09VY9BT1fxaGGwyWvAdPXqUTp06Ubt2bQ4f\nPszs2bP55JNPuPrqq92OZiJYrmMIIrIX+AEYBryqqr+LyHeqeixo6cwZvq5jlNW9k9uAc+FCwuUX\nXcDh4+mUuKQIh46lex2ctslowbd48WLi4uLYvXs3rVu3pk+fPhQrluvtSYzxG28thCnA9Xi6hxqL\nyKXY4nOu6dzoNooWyfv68n2HjnttTQx4oipvNqnE9SWKcjCXYnDphYVtMpoLDh06RFxcHPfddx+F\nChVi6dKlDB061IqBCRpvVxl1EJGOwL3AP4F+QHEReRL4QlX/yO2zxv/OnoOQm6zunZz2KeW8l9fk\nthKXXMi2t2xCWjDNmDGD1q1b88svv9ClSxfefPNNiha1rjoTXHldZaSqukRV44FywDPAo3jGFEyQ\nZc1B8KZzo9tybE1kdf34Mjhtg8jBs3//fp5++mmaNm1KyZIlWbt2LX379rViYFzh8920VTVdVWep\n6r+AMgHMZPJQomiRHLcXLVKIptVL0bR6Kd5pVjnHdYh8+WVvg8iBp6qMGzeOihUrMm3aNHr16kVi\nYiIxMTFuRzMFmLdB5VuA7sABYCCeRe3uBr7Fc8VRYjACmr96s0klOk/eRHrm/0YAihQS3mlW5czr\nrMJwtrwGp20QOfB+/PFHXnzxRb744gvuvPNOEhISiIqKcjuWMV5bCP8FVgH7gLXAGOBq4FVgSOCj\nmdw0rV6K/k9U/VMLoP8TVX0a/M2pOynrElUbRA6szMxMhg0bRqVKlVi6dCmDBg1ixYoVVgxMyJAc\nFjT1vCGyUVWrOc93qerNOb0XTDExMZqYaA2T/MpaAsPuixw8O3bsoGXLlixfvpwGDRowcuRIypUr\n53YsU0CIyAZVzbM/0ttqp5nZnh/x8p4JM7l1Jxn/O336NAMHDqRHjx5cfPHFjBkzhueff95mGpuQ\n5K0gVBCRzXh6FMo7z3Fe3xTwZMaEuU2bNtGiRQuSkpL4xz/+wZAhQ7juuuvcjmVMrrwVhIqBPLGI\nlAE+Bq7FM+FtpKq+H8hzGhMMJ0+e5O2336ZPnz5ceeWVTJ48mccee8xaBSbkeZuY9n2Az30aeEVV\nk0TkcmCDiCxQ1ZQAn9eYgFm9ejWxsbFs376dZ599loEDB3LVVVe5HcsYn/g8D8HfVPUnVU1ynv8O\nbAesY9uEpT/++IMOHTpQt25djh49yty5c/noo4+sGJiw4q3LKGhEpCye22mudTeJMeduwYIFxMfH\ns2fPHtq2bUvv3r25/PLL3Y5lzDlzrYWQRUQuAz4HOqjq2VczISLxIpIoIolpaWnBD2hMLg4ePEiL\nFi1o2LAhF110EcuXL2fw4MFWDEzYyrMgiEhdEVkgIjtEZLeIfCciu/1xchEpgqcYfKqqU3PaR1VH\nqmqMqsaULFnSH6c1Jt+mTZtGVFQUH3/8Md26dWPjxo3cddddbscyJl986TJKADoCG4C8b9nlI/Fc\ncpEAbFfVgf46rjGB9PPPP/Pyyy8zZcoUqlWrxpw5c6hRo4bbsYzxC1+6jA6r6lxV3a+qv2U9/HDu\nusD/AfVFZKPzeMgPxzXG71SVjz76iKioKGbNmkXv3r1Zt26dFQMTUbwtbpf1L32JiPQHpgIns97P\nukLofKnqCgJzC2Bj/Or777+nVatWzJ8/nzp16pCQkECFChXcjmWM33nrMhpw1uvs62AoYHdQMREt\nMzOToUOH0rVrVwAGDx7MSy+9RKFCrl+LYUxAeJuYVg9ARG5S1T8NIouILV1hIto333xDbGwsK1eu\npFGjRowYMYIbb7zR7VjGBJQvX3Wm5LBtsr+DGBMK0tPTeeedd6hatSopKSmMHTuWuXPnWjEwBYK3\nMYQKQCU891Fulu2tYsDFgQ5mTLAlJycTGxtLcnIyjz/+OIMHD+Zvf/ub27GMCRpvYwi3AY8AJYDG\n2bb/DsQFMpQxwXTixAneeust+vXrx9VXX83nn39Os2bN8v6gMRHG2xjCDGCGiNRW1dVBzGRM0KxY\nsYLY2Fh27NjBCy+8wIABA7jiiivcjmWMK3yZmBYvIn9pEahqiwDkMSYofv/9d7p168aQIUMoW7Ys\n8+fPp2HDhm7HMsZVvhSE2dmeXwz8A899lo0JS/Pnzyc+Pp4ff/yRdu3a8Z///IfLLrvM7VjGuC7P\ngqCqn2d/LSLjgRUBS2RMgBw4cICOHTvy8ccfU6FCBVasWEGdOnXcjmVMyDifGTa3ANf4O4gxgaKq\nTJkyhYoVK/LZZ5/RvXt3kpOTrRgYc5Y8Wwgi8juemclZfgZeC1giY/zop59+ok2bNkybNo0aNWow\nf/58qlWr5nYsY0KS14LgrEhaSVV/CFIeY/xCVRk7diydOnXixIkT9O3bl06dOnHBBSFxTyhjQpLX\nLiNVVWBOkLIY4xffffcdDRs2pEWLFlSuXJlNmzbRpUsXKwbG5MGXMYQkEbkj4EmMyaeMjAw++OAD\noqOjWbNmDUOHDmXp0qXceuutbkczJiz48pWpFvAvEfkeOIpnyWpV1SoBTWbMOdi+fTuxsbGsXr2a\nBx98kOHDh3PDDTe4HcuYsOJLQWgU8BTGnKf09HT69u1Lr169uOyyy/jkk0/417/+hWf4yxhzLnzp\nMnpbVb/P/gDe9sfJRWSMiOwXka3+OJ4pWDZs2EBMTAz//ve/adq0Kdu3b6d58+ZWDIw5T74UhErZ\nX4hIYeB2P51/LPCAn45lCojjx4/z2muvUbNmTdLS0pg2bRoTJ07kmmtseowx+ZFrQRCRbs4chCoi\ncsR5/A7sB2b44+Squgw44I9jmYJh2bJlVK1alX79+tGiRQtSUlJo2rSp27GMiQi5FgRVfUdVLwf6\nq2ox53G5ql6lqt2CmNEYjhw5wksvvcQ999zD6dOnWbhwIaNGjaJEiRJuRzMmYuTZZeT2L38RiReR\nRBFJTEtLczOKcckXX3xBpUqVGD58OB07dmTLli3cd999bscyJuKE/N3CVXWkqsaoakzJkiXdjmOC\n6Ndff6V58+Y8/PDDFCtWjFWrVjFw4EAuvfRSt6MZE5FCviCYgkdVmThxIlFRUUycOJE33niDpKQk\n7rzzTrejGRPRvN1T+UpvH1TVfA8GO0tp3wtcLSJ7gR6qmpDf45rwtW/fPlq3bs3MmTOJiYlh4cKF\nVKlicyCNCQZvE9M24FnlVIAbgIPO8xLAD0C5/J5cVf+Z32OYyKCqJCQk8Oqrr3Ly5Eneffdd2rdv\nb+sPGRNE3q4yKqeqNwELgcaqerWqXgU8AnwZrIAm8u3evZsGDRoQFxdHtWrV2LJlC6+88ooVA2OC\nzJcxhDtV9YusF6o6F7A7i5h8y8jI4L333iM6Opr169czYsQIFi9ezM033+x2NGMKJF++gu0TkdeB\ncc7rf2H3VDb5tHXrVmJjY1m3bh0PP/www4cPp3Tp0m7HMqZA86WF8E+gJDDNeVzjbDPmnJ06dYqe\nPXtSo0YNdu/ezWeffcasWbOsGBgTAvJsIThXE7UPQhYT4davX0+LFi3YunUrzzzzDIMGDcLmlhgT\nOny5p/KtwKtA2ez7q2r9wMUykeTYsWO88cYbvPfee1x33XXMnDmTxo0bux3LGHMWX8YQJgPDgdFA\nRmDjmEizdOlSWrZsybfffkurVq3o27cvxYsXdzuWMSYHvhSE06o6LOBJTEQ5fPgwXbp0YeTIkZQv\nX57FixdTr149t2MZY7zwZVB5loi8JCLXiciVWY+AJzNha9asWURFRTF69GheffVVNm/ebMXAmDDg\nSwvhOee/nbNtU+Am/8cx4SwtLY327dszfvx4KleuzPTp07njjjvcjmWM8ZEvVxnle4kKE9lUlfHj\nx9OuXTuOHDlCz5496dq1KxdeeKHb0Ywx58CXq4yezWm7qn7s/zgm3Ozdu5fWrVsze/ZsatWqRUJC\nApUqVcr7g8aYkONLl1H2Nv/FwH1AEmAFoQDLzMxk1KhRdO7cmdOnTzNw4EDatWtH4cKF3Y5mjDlP\nvnQZvZz9tYiUACYELJEJeTvyzPYRAAASd0lEQVR37iQuLo6vvvqK+vXrM2rUKG66yYaUjAl353OD\nnKP4YelrE35Onz7Nu+++S5UqVUhOTmbUqFEsXLjQioExEcKXMYRZeK4qAigMVAQmBTKUCT2bN28m\nNjaWxMREmjRpwtChQylVqpTbsYwxfuTLGMK72Z6fBr5X1b3+OLmIPAC8j6fQjFbVPv44rvGfkydP\n0rt3b3r37s0VV1zBxIkTeeKJJxARt6MZY/zMlzGEr0TkWv43uLzTHycWkcLAEOB+YC+wXkRmqmqK\nP45v8m/NmjXExsaSkpJC8+bNGTRoEFdddZXbsYwxAZLnGIKIPAmsA54AngTWisjjfjh3TWCXqu5W\n1VN4Bqof9cNxTT4dPXqUTp06UadOHY4cOcKcOXP45JNPrBgYE+F86TLqDtyhqvsBRKQknttqTsnn\nuUsBP2Z7vReodfZOIhIPxAPccMMN+TylycuiRYuIi4vju+++o3Xr1vTp04dixYq5HcsYEwS+XGVU\nKKsYOH7z8XN+oaojVTVGVWNs7fzAOXToEC1btqRBgwZccMEFfPXVVwwdOtSKgTEFiC8thHkiMh8Y\n77x+CvjCy/6+SgXKZHtd2tlmgmzGjBm0bt2a/fv389prr9GjRw+KFi3qdixjTJD5MqjcWUSaAXc5\nm0aq6jQ/nHs9cIuIlMNTCJ4GnvHDcY2PfvnlF9q1a8ekSZOoWrUqs2bN4vbbb3c7ljHGJV4LgnMl\n0EJVrQdM9eeJVfW0iLQF5uO57HSMqm7z5zlMzlSVcePG0aFDB/744w/efvttunTpQpEiRdyOZoxx\nkdeCoKoZIpIpIsVV9bC/T66qX+Cf7ifjox9++IEXX3yRuXPnUrt2bRISEqhYsaLbsYwxIcCXMYQ/\ngC0isgDPshUAqGq7gKUyfpeZmcnw4cN57bXXyMzM5P3336dNmza2GJ0x5gxfCsJU/NxdZIJrx44d\ntGzZkuXLl9OgQQNGjhxJuXK2HJUx5s98GVT+KBhBjP+dPn2aAQMGnLlqaMyYMTz//PO27IQxJke5\nzicQkUdFpE2212tFZLfz8MdMZRNAmzZtolatWnTt2pWHHnqIlJQUXnjhBSsGxphceZtg1gWYme31\nRXjWM7oXaB3ATCYfTpw4weuvv05MTAypqalMmTKFqVOnct1117kdzRgT4rx1GV2oqtmXllihqr8B\nv4nIpQHOZc7DqlWriI2N5euvv+a5555j4MCBXHnllW7HMsaECW8thCuyv1DVttle2hoSIeSPP/6g\nXbt23HXXXRw7dox58+YxduxYKwbGmHPirSCsFZG4szeKSCs8q5+aEPDll18SHR3Nhx9+SJs2bdi6\ndSuNGjVyO5YxJgx56zLqCEwXkWeAJGfb7XjGEpoGOpjx7uDBg3Tq1ImxY8dy2223sWzZMu666668\nP2iMMbnItSA4K5zWEZH6QCVn8xxVXRyUZCZXU6dOpU2bNqSlpdGtWzfeeOMNLr74YrdjGWPCnC/z\nEBYDVgRCwM8//0zbtm35/PPPqVatGl988QXVq1d3O5YxJkIE7b4G5vypKmPHjiUqKorZs2fTu3dv\n1q1bZ8XAGONXvixdYVy0Z88eWrVqxZdffkndunUZPXo0FSpUcDuWMSYCWQshRGVmZjJ48GCio6NZ\ntWoVH374IcuWLbNiYIwJGGshhKCvv/6ali1bsnLlSho1asSIESO48cYb3Y5ljIlw1kIIIenp6fTu\n3ZuqVauSkpLCRx99xNy5c60YGGOCwpWCICJPiMg25+Y7MW5kCDVJSUnUrFmT7t2706RJE7Zv386z\nzz5ri9EZY4LGrRbCVqAZsMyl84eM48eP061bN2rWrMnPP//M559/zuTJk7n22mvdjmaMKWBcGUNQ\n1e1Agf/2u2LFCmJjY9mxYwcvvPACAwYM4Iorrsj7g8YYEwAhP4YgIvEikigiiWlpaW7H8Yvff/+d\ntm3bcvfdd3Pq1Cm+/PJLxowZY8XAGOOqgBUEEVkoIltzeDx6LsdR1ZGqGqOqMSVLhv8iq/PmzSM6\nOpqhQ4fSvn17tmzZwv333+92LGOMCVyXkao2CNSxw9Fvv/1Gp06d+Pjjj6lYsSIrV66kdu3abscy\nxpgzQr7LKNypKpMnTyYqKorPPvuM119/neTkZCsGxpiQ49Zlp/8Qkb1AbWCOiMx3I0eg/fTTTzRr\n1ownn3ySMmXKkJiYSK9evbjooovcjmaMMX/hSkFQ1WmqWlpVL1LVa1U1ou7ooqqMGTOGihUrMm/e\nPPr27cuaNWuoWrWq29GMMSZXtnSFn3333XfEx8ezcOFC/v73vzNq1ChuvfVWt2MZY0yebAzBTzIy\nMnj//feJjo5m7dq1DBs2jCVLllgxMMaEDWsh+EFKSgqxsbGsWbOGBx98kBEjRlCmTBm3YxljzDmx\nFkI+nDp1il69elG9enV27tzJuHHjmDNnjhUDY0xYshbCeUpMTCQ2NpbNmzfz1FNP8cEHH3DNNde4\nHcsYY86btRDO0fHjx+nSpQu1atXi119/Zfr06UyYMMGKgTEm7FkL4Rx89dVXtGzZkl27dhEXF0e/\nfv0oUaKE27GMMcYvrIXggyNHjtC6dWvuvfdeMjMzWbRoESNHjrRiYIyJKFYQ8jBnzhwqVarEyJEj\n6dSpE5s3b6Z+/fpuxzLGGL+zgpCLX3/9lebNm/PII49QrFgxVq1axYABA7j00kvdjmaMMQFhBeEs\nqsqECROoWLEiEydOpEePHiQlJVGrVi23oxljTEDZoHI2qampvPTSS8ycOZM77riDhIQEKleu7HYs\nY4wJCmsh4GkVjBo1iqioKBYsWMC7777L6tWrrRgYYwqUAt9C+Pbbb4mLi2PJkiXce++9jBo1iptv\nvtntWMYYE3QFtoWQkZHBwIEDqVy5Mhs2bGDEiBEsWrTIioExpsBypYUgIv2BxsAp4FvgBVU9FKzz\nb926ldjYWNatW8cjjzzCsGHDKF26dLBOb4wxIcmtFsICIFpVqwA7gG7BOOmpU6fo2bMnNWrUYPfu\n3Xz22WfMnDnTioExxuBSC0FVv8z2cg3weKDPuW7dOmJjY9m6dSvPPPMMgwYNomTJkoE+rTHGhI1Q\nGENoAcwN5AnefvttateuzcGDB5k1axaffvqpFQNjjDlLwFoIIrIQ+FsOb3VX1RnOPt2B08CnXo4T\nD8QD3HDDDeeVpXz58sTFxdG3b1+KFy9+XscwxphIJ6rqzolFngdaAfep6jFfPhMTE6OJiYkBzWWM\nMZFGRDaoakxe+7l1ldEDQBfgHl+LgTHGmMByawzhQ+ByYIGIbBSR4S7lMMYY43DrKiOb/WWMMSEm\nFK4yMsYYEwKsIBhjjAGsIBhjjHFYQTDGGANYQTDGGONwbWLa+RCRNOD78/z41cCvfozjL5br3Fiu\nc2O5zk2o5oL8ZbtRVfNcryesCkJ+iEiiLzP1gs1ynRvLdW4s17kJ1VwQnGzWZWSMMQawgmCMMcZR\nkArCSLcD5MJynRvLdW4s17kJ1VwQhGwFZgzBGGOMdwWphWCMMcaLAlUQRKS/iHwtIptFZJqIlHA7\nE4CIPCEi20QkU0Rcv8JBRB4QkW9EZJeIdHU7D4CIjBGR/SKy1e0s2YlIGRFZIiIpzt9he7czAYjI\nxSKyTkQ2Obl6up0pOxEpLCLJIjLb7SxZRGSPiGxxVmAOmRuviEgJEZni/O7aLiK1A3WuAlUQgAVA\ntKpWAXYA3VzOk2Ur0AxY5nYQESkMDAEeBKKAf4pIlLupABgLPOB2iBycBl5R1SjgTqBNiPy8TgL1\nVbUqUA14QETudDlTdu2B7W6HyEE9Va0WYpeevg/MU9UKQFUC+HMrUAVBVb9U1dPOyzVAaTfzZFHV\n7ar6jds5HDWBXaq6W1VPAROAR13OhKouAw64neNsqvqTqiY5z3/H8z9rKXdTgXr84bws4jxCYsBQ\nREoDDwOj3c4S6kSkOPB3IAFAVU+p6qFAna9AFYSztADmuh0iBJUCfsz2ei8h8AsuHIhIWaA6sNbd\nJB5Ot8xGYD+wQFVDIhcwCM8dEzPdDnIWBb4UkQ3OvdxDQTkgDfiv08U2WkQuDdTJIq4giMhCEdma\nw+PRbPt0x9PU/zSUcpnwJSKXAZ8DHVT1iNt5AFQ1Q1Wr4WkJ1xSRaLczicgjwH5V3eB2lhzcpao1\n8HSXthGRv7sdCM9NzGoAw1S1OnAUCNi4nit3TAskVW3g7X0ReR54BLhPg3jNbV65QkgqUCbb69LO\nNpMLESmCpxh8qqpT3c5zNlU9JCJL8IzBuD0oXxdoIiIPARcDxURknKo2dzkXqprq/He/iEzD033q\n9rjeXmBvttbdFAJYECKuheCNiDyAp6naRFWPuZ0nRK0HbhGRciJyIfA0MNPlTCFLRARP/+52VR3o\ndp4sIlIy6yo6ESkK3A987W4qUNVuqlpaVcvi+be1OBSKgYhcKiKXZz0HGuJ+8URVfwZ+FJHbnE33\nASmBOl+BKgjAh8DlwALn0rLhbgcCEJF/iMheoDYwR0Tmu5XFGXRvC8zHM0A6SVW3uZUni4iMB1YD\nt4nIXhGJdTuToy7wf0B959/URufbr9uuA5aIyGY8RX6BqobMJZ4h6FpghYhsAtYBc1R1nsuZsrwM\nfOr8XVYDegfqRDZT2RhjDFDwWgjGGGNyYQXBGGMMYAXBGGOMwwqCMcYYwAqCMcYYhxUEE3QikuFc\nnrlVRCaLyCX5ONa9WStmikgTb6uzOqtGvnQe53hTRF7NZXuq82f5WkSGiUihbO9fICJpItLnrM8V\nEZE+IrJTRJJEZLWIPOi8l33FzY0i8sE55Dzzs3BePygiic5KrMkiMsDZ/ryTK+scLbN95jkn104R\nee7cflIm3FlBMG447qwoGQ2cAl7M/qZ4nPO/TVWdqap9vOxSAjjngpCH95zlIaKAysA92d67H8+q\nuk84E9iy9MIzTyDaWSqhKZ75MVmyVtyspqrtzieUs0zFh0BzZyXWGGBXtl0mZjvHaOczVwI9gFp4\nZun2EJErzuf8JjxZQTBuWw7cLCJlxXMPho/xzBAtIyINnW/PSU5L4jI4c7+Gr0UkCc+y4TjbnxeR\nD53n14rnnhebnEcdoA9Q3vlW3N/Zr7OIrBfPPTJ6ZjtWdxHZISIrgNvI24V4lmI4mG3bP/EsXfwD\nnkmHOK2hOOBlVT0JoKq/qOokX39gIjJWRIY73/53OOsDna0L8B9V/do5R4aqDsvj0I3wTGA7oKoH\n8SwXH4pLjpsAsYJgXCMiF+BZSGyLs+kWYKiqVsKziNfrQAPnW3Qi0ElELgZGAY2B24G/5XL4D4Cv\nnPsB1AC24VkD5lvnW3FnEWnonLMmnhmgt4vI30XkdjzLKlQDHgLu8PLH6CieFUV/Anao6kbnz3Yx\n0ACYBYzHUxwAbgZ+yGMBvCXZunM65rJPWSf3w8Bw53zZRQPeFpB7zCmCU0Qka+0qW+m2gLOCYNxQ\n1Pklmojn23OCs/17VV3jPL8TTzfMSmff54AbgQrAd6q601mccFwu56gPDIMz344P57BPQ+eRDCQ5\nx74FuBuYpqrHnF/c3tZyyuoyuga4VESedrY/AixR1eN4Fr5rKp6bD/kie5fRe7nsM0lVM1V1J7Db\nye6rWUBZ50ZRC4CPzuGzJoJF3GqnJiwcd36JnuF0sR/NvglP98U/z9rvT5/LJwHeUdURZ52jw7ke\nSFXTRWQenpuZTMDTIrhLRPY4u1yFp0itBG4QkWL5XCb77DVnzn69DU8LalMOWX/L9nI00M95ngrc\nm+290sDSfGQ0YcZaCCZUrQHqisjNcGY1ylvxrNhZVkTKO/v9M5fPLwJaO58tLJ47T/3Onwdv5wMt\nso1NlBKRa/AsedxURIqKZwXMxnmFdQaN6wLfikgxPK2MG1S1rLOyZxvgn84quwnA++JZTTZrZdIn\nfPuxnPGEiBRyfg43AWffca8/8P+cnxnOvi86z6/Ltl8T/ndLxvlAQxG5whlMbuhsMwWEtRBMSFLV\nNPHcu2K8iFzkbH5dVXeI525Wc0TkGJ5B6ctzOER7YKR4VkXNAFqr6moRWSkiW4G5zjhCRWC100L5\nA89VOUkiMhHPt+v9eFYLzU1HEWmO5xaVm4GhwJN4lnU+mW2/GUA/58/yOvA2kCIiJ/C0jN7Itu8S\nEclwnm9W1WdzOO8PeFblLAa8qKonsl/IpKqbnZbOeGcgW4GsS1LbiUgTPDeJOgA873zmgIj0yvbn\nfUtVQ+62pSZwbLVTY8KMiIwFZqvqFLezmMhiXUbGGGMAayEYY4xxWAvBGGMMYAXBGGOMwwqCMcYY\nwAqCMcYYhxUEY4wxgBUEY4wxjv8P7jeoXTB9bnIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDdJwuFdQa9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scatterplot for visualizing progress of property prediction models (BACE)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Load the dataset ==> can use 1 dataframe with seen and unseen as different colors -> bool\n",
        "def plot_gt_pred_scatter(history, itr):    \n",
        "    pred_df = history[itr][\"selected_prediction\"]\n",
        "\n",
        "    for prop in (\"bace\", \"esol\", \"logD\"):\n",
        "        act = ground_truth_dataset.sort_values(by=\"SMILES\")[prop].tolist()\n",
        "        pred = pred_df.sort_values(by=\"SMILES\")[prop].tolist()\n",
        "        seen_smiles = history[itr][\"smiles_seen\"]\n",
        "        seen_list = ground_truth_dataset.sort_values(by='SMILES')['SMILES'].isin(seen_smiles).tolist()\n",
        "\n",
        "        plot_df = pd.DataFrame({\"Ground Truth Value\":act,\"Model Predicted Value\":pred,\"Sample seen?\":seen_list})\n",
        "\n",
        "        # Draw a scatter plot assigning pt colors and sizes to diff vars in dataset\n",
        "        f, ax = plt.subplots(figsize=(6.5, 6.5))\n",
        "        x = np.linspace(-10,10,1000)\n",
        "        \n",
        "        if prop == \"bace\":\n",
        "            sns.scatterplot(x=\"Ground Truth Value\", y=\"Model Predicted Value\", hue=\"Sample seen?\", hue_order=[True,False], palette={True:\"blue\",False:\"lightgrey\"},\n",
        "                            linewidth=0, data=plot_df, ax=ax, alpha=0.5)\n",
        "            plt.xlim(-4,5.5)\n",
        "            plt.ylim(-4,5.5)\n",
        "            \n",
        "        elif prop == \"esol\":\n",
        "            sns.scatterplot(x=\"Ground Truth Value\", y=\"Model Predicted Value\", hue=\"Sample seen?\", hue_order=[True,False], palette={True:\"blue\",False:\"lightgrey\"},\n",
        "                            linewidth=0, data=plot_df, ax=ax, alpha=0.5)\n",
        "            plt.xlim(-6,4)\n",
        "            plt.ylim(-6,4)\n",
        "            \n",
        "        elif prop == \"logD\":\n",
        "            sns.scatterplot(x=\"Ground Truth Value\", y=\"Model Predicted Value\", hue=\"Sample seen?\", hue_order=[True,False], palette={True:\"blue\",False:\"lightgrey\"},\n",
        "                            linewidth=0, data=plot_df, ax=ax, alpha=0.5)\n",
        "            plt.xlim(-4,3)\n",
        "            plt.ylim(-4,3)\n",
        "        \n",
        "        plt.plot(x,x)\n",
        "        #plt.show()\n",
        "        filename=f'../images/mean_plot_{prop}_{itr}.png'\n",
        "        plt.savefig(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V10S6guS8qcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My\\ Drive/models\n",
        "!ls\n",
        "\n",
        "with open(\"mean_model_25.pickle\",'rb') as infile:\n",
        "    data = pickle.load(infile)\n",
        "\n",
        "#print(data[1][\"selected_prediction\"])\n",
        "for itr in (1,13,25):\n",
        "    plot_gt_pred_scatter(data,itr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RE2HqcP_Hox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7161bc68-99c9-4f6e-a630-c9fc6474fa8f"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(actual,predicted):\n",
        "    return np.sqrt( mean_squared_error(actual, predicted) )\n",
        "\n",
        "# Load the dataset ==> can use 1 dataframe with seen and unseen as different colors -> bool\n",
        "\n",
        "def get_all_rmse(history):\n",
        "    pred_df = history[itr][\"selected_prediction\"]\n",
        "    act = ground_truth_dataset.sort_values(by=\"SMILES\")[prop].tolist()\n",
        "    pred = pred_df.sort_values(by=\"SMILES\")[prop].tolist()\n",
        "\n",
        "    rmse = get_rmse(act,pred)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.8544024072957406\n",
            "4.671728152730213\n",
            "0.5822508261698716\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}